[
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "",
    "text": "In this blog post, I’ll show how I used Julia and a GPT-3 model (via an online API) in an attempt to analyze the monetary value of items in the Harry Potter novels, and what I learned in the process."
  },
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html#harry-potter-and-money",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html#harry-potter-and-money",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "Harry Potter and money",
    "text": "Harry Potter and money\nAnybody who has read the Harry Potter books has probably noticed how the monetary value of items in the wizarding world is a bit… inconsistent at times. For example, the Weasley family has only a single gold coin in their vault, while a wand costs seven Galleons, and special fireworks from the Weasley twins in the later books ten Galleons. We don’t know how much time or effort it takes to make a wand, but probably more than mass produced fireworks, and I hope the Weasleys would have been able to afford food and clothes equaling fireworks in value.\nI have sometimes wondered about how inconsistent the books really are in this point. So I wanted to visualize how the value of items mentioned across the books develops over time, because my hypothesis was that J.K. Rowling might have added more and more expensive things while she was writing, just to contrast them against previously introduced items. For example, something relatively expensive in the first book (the wand) looks very cheap compared to later items (the fireworks).\nMy initial plan for this exercise was to extract all prices from the books and plot them over time (position in the books) or in a sorted bar graph on a logarithmic axis to related all the things you could buy in the wizarding world. However, I never got there because the more interesting part proved to be how to assemble the list of items of value in the first place, without manually going through all the books.\n(In the end, I could have just googled anyway, and would have found the table on this page, but that would not have been as much fun!)"
  },
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html#preparing-the-data",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html#preparing-the-data",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "Preparing the data",
    "text": "Preparing the data\nFirst of all, I downloaded the Harry Potter plain text corpora from kaggle.com and extracted them into a folder, deleting the attached list of characters.\nThen, I loaded all seven of them into a string:\nusing DataFrames\nusing JSON3\nusing HTTP\nusing CSV\nusing Chain\nusing DataFrameMacros\n\n\ncorpus = @chain begin\n    readdir(\"archive\", join = true)\n    read.(String)\n    join\n    replace(r\"(\\n *){2,}\" =&gt; \"\\n\")\n    replace(r\"^Page \\|.*$\"m =&gt; \"\")\nend\nThe last two replace calls remove superfluous line breaks and page number annotations. With that, I had a reasonably clean starting point.\nNext, I wanted to find all the places in the books where the wizarding currency was mentioned. I achieved this by looking for Galleons, Sickles and Knuts via regular expression:\nsnippet_ranges = @chain begin\n    findall(r\"galleon|sickle|knut\"i, corpus)\n    foldl(_[2:end], init = _[1:1]) do list, rng\n        if abs(list[end].stop - rng.start) &lt; 300\n            list[end] = list[end].start:rng.stop\n        else\n            push!(list, rng)\n        end\n        list\n    end\n    [x.start-300:x.stop+300 for x in _]\nend\nThe foldl command takes the list of occurrence ranges found and merges entries less than 300 characters apart together. That’s because I assumed that often, multiple money related words would be found in a coherent paragraph. I stored the merged ranges with some additional 300 character padding before and after, for context. I found 98 snippets like this.\nWith a helper function, I could then cut out snippets from the corpus.\nsnippet(corpus, range) = corpus[prevind(corpus, range.start):nextind(corpus, range.stop)]\nNote that I used the prevind and nextind functions to shift the stored indices to the next valid indices in the UTF string. I only did this after some snippets failed to extract, as I had assumed most of Harry Potter would be ASCII anyway and the naive 300 character shift would be ok (it wasn’t).\nHere’s one example of using the function on the corpus:\njulia&gt; snippet(corpus, snippet_ranges[2]) |&gt; print\nht more eyes. He \nturned his head in every direction as they walked up \nthe street, trying to look at everything at once: the \nshops, the things outside them, the people doing their \nshopping. A plump woman outside an Apothecary \nwas shaking her head as they passed, saying, \n“Dragon liver, sixteen Sickles an ounce, they’re mad.” \nA low, soft hooting came from a dark shop with a sign \nsaying Eeylops Owl Emporium — Tawny, Screech, \nBarn, Brown, and Snowy. Several boys of about \nHarry’s age had their noses pressed against a window \nwith broomsticks in it. “Look,” Harry heard one of \nthem sa\nAn English speaker reading this should be able to extract the item of value being talked about in this paragraph: Dragon liver for sixteen Sickles.\nOf course I didn’t want to manually go through all 98 snippets, so I thought about ways to extract the data I needed automatically. Carefully constructed regexes are usually closer to my mode of thinking than more opaque machine learning methods, but in this case it was pretty clear that there was no generally exploitable sentence structure to extract both the price and the item. Sometimes the item is mentioned three sentences before the price, or only alluded to. Therefore, I thought, why not try one of the fancy language models that are talked about so much these days. Would I be able to automate the task with them?"
  },
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html#using-gpt-3",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html#using-gpt-3",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "Using GPT-3",
    "text": "Using GPT-3\nBecause I didn’t even want to attempt running models on my laptop, I looked into using a web API to feed my data to a language model. I settled on beta.openai.com/playground which offers some free credits to start with and was relatively painless to get working.\nI briefly played around with the user interface on the site to come up with a suitable prompt. My goal was to make the model extract a CSV table of items with their price separated by Galleons, Sickles and Knuts. After 10 minutes or so of prompt engineering, I settled on this version:\nfunction prompt(snippet)\n    \"\"\"\n    The following is a text snippet from Harry Potter. One or several items are mentioned, together with their prices in galleons, sickles and knuts.\n\n    Return a comma-separated table with the column headers Item, Galleons, Sickles, Knuts.\n    \n    Example input:\n\n    #########\n    ...After visiting Diagon Alley, Harry bought a spell book for three Galleons\n    and fourteen Sickles, as well as a wand made of chocolate which cost him\n    two Sickles and three Knuts...\n    #########\n\n    Example output:\n\n    Item,Galleons,Sickles,Knuts\n    \"Spell Book\",3,14,0\n    \"Chocolate Wand\",0,2,3\n\n    Input:\n\n    #########\n    ...$snippet...\n    #########\n\n    Result:\n\n    \"\"\"\nend\nHere’s what the model’s output was for the snippet mentioned above:\nItem,Galleons,Sickles,Knuts\n\"Dragon Liver\",0,16,0\n\"Broomsticks\",0,0,0\nFirst of all, I was very impressed that the model managed to output valid CSV, and that “Dragon Liver” for sixteen Sickles was extracted correctly.\nInterestingly, this snippet also produced “Broomsticks” for zero Galleons. The relevant sentence in the snippet is “Several boys of about Harry’s age had their noses pressed against a window with broomsticks in it.”. Broomsticks are mentioned, and they clearly are something of value, being displayed in a shop’s window. But the price isn’t mentioned so of course it would be silly for a human to include the item in the list.\nThis already foreshadowed how the overall data extraction would fare."
  },
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html#using-the-gpt-3-api",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html#using-the-gpt-3-api",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "Using the GPT-3 API",
    "text": "Using the GPT-3 API\nTo automatically run the model against every snippet in my database, I used the following function:\nfunction get_response(snippet)\n    p = prompt(snippet)\n    response = HTTP.post(\n        \"https://api.openai.com/v1/completions\",\n        Dict(\n            \"Content-Type\" =&gt; \"application/json\",\n            \"Authorization\" =&gt; \"Bearer $(read(\"token.txt\", String))\"\n        ),\n        JSON3.write(Dict(\n            :model =&gt; \"text-davinci-002\",\n            :prompt =&gt; p,\n            :temperature =&gt; 0.1,\n            :max_tokens =&gt; 50,\n        ))\n    )\n    s = String(response.body)\n    JSON3.read(s).choices[1].text\nend\nMy account’s API token was stored in a separate text file, you’ll have to get your own if you want to try this out as well. I chose \"text-davinci-002\" as the model which is supposed to be the most capable. I had to set temperature and max_tokens to something lower and higher than the defaults, respectively, until the test responses looked good. If the number of tokens is too low, the full table will not print.\nI then ran this function for all the items in my collection, taking care not to exceed 60 requests per minute as the requests started failing due to rate limiting the first time I tried it.\nresults = map(enumerate(snippet_ranges)) do (i, snippet_range)\n    t = time()\n    snip = snippet(corpus, snippet_range)\n    println(\"\\n\\n\\n\\n$i of $(length(snippet_ranges))\")\n    println(snip)\n    response = get_response(snip)\n    println(response)\n    # rate limit 60/min\n    sleep(max(0, 1 - (time() - t)))\n    (; snippet_range, snippet = snip, response)\nend\n\n# turn the ranges into tuples so the json output doesn't include a zillion numbers\nresults_corrected = map(results) do result\n    (; snippet_range = (result.snippet_range.start, result.snippet_range.stop),\n        result.snippet, result.response)\nend\n\nJSON3.write(\"results.json\", results_corrected)\n\nFinally, I parsed each response as a CSV and concatenated them all into a big DataFrame:\ndf = @chain begin\n    map(results_corrected) do result\n        CSV.read(IOBuffer(result.response), DataFrame)\n    end\n    reduce(vcat, _, source = :snippet_id, cols = :union)\n    sort!([:Galleons, :Sickles, :Knuts], rev = true)\n    @transform! @subset(:Knut !== missing) :Knuts = :Knut\n    # @subset !(:Galleons == :Sickles == :Knuts == 0)\n    select(Not(:Knut))\nend\n\nCSV.write(\"result_df.csv\", df)\nOne entry had the column Knut instead of Knuts so I fixed this, other than that the format of the table appeared to be followed correctly for each entry. I was already quite impressed by that.\nBut let’s have a look at the results:\n\nThe top of the list looks good at first, the prize money for the Triwizard Cup was indeed 1000 Galleons. A few entries further down, however, we see “Goblet of Fire entry fee”. The goblet itself didn’t have an entry fee and the entry fee also wasn’t a thousand Galleons, so this is obviously wrong. We can have a look at the snippet:\njulia&gt; print(snippet(corpus, snippet_ranges[34]))\n me the truth,” he \nsaid. “If you don’t want everyone else to know, fine, \nbut I don’t know why you’re bothering to lie, you \ndidn’t get into trouble for it, did you? That friend of \nthe Fat Lady’s, that Violet, she’s already told us all \n\nDumbledore’s letting you enter. A thousand Galleons \nprize money, eh? And you don’t have to do end-of- \nyear tests either. ...” \n“I didn’t put my name in that goblet!” said Harry, \nstarting to feel angry. \n“Yeah, okay,” said Ron, in exactly the same sceptical \ntone as Cedric. “Only you said this morning you’d \nhave done it last nig\nThe language here is not ambiguous for a human, even with no background knowledge, the thousand Galleons are clearly prize money and not an entry fee, even if for an uninformed reader it would not be clear what the prize money is for. One other interesting fact is that the snippet never mentions that it’s a goblet of fire, so this part is clearly knowledge that the model added itself.\nThe next glaring error are the Canary Creams for a whopping 1000 Galleons. Let’s have a look at the snippet:\njulia&gt; print(snippet(corpus, snippet_ranges[40]))\nld do with a few laughs. We could all \n\nHarry Potter and the Goblet of Fire - J.K. Rowling \ndo with a few laughs. I’ve got a feeling we’re going to \nneed them more than usual before long.” \n“Harry,” said George weakly, weighing the money bag \nin his hands, “there’s got to be a thousand Galleons \nin here.” \n“Yeah,” said Harry, grinning. “Think how many \nCanary Creams that is.” \nThe twins stared at him. \n“Just don’t tell your mum where you got it ... \nalthough she might not be so keen for you to join the \nMinistry anymore, come to think of it. ...” \n“Harry,” Fred began, \nThis one’s interesting, because technically this passage does talk about 1000 Galleons worth of Canary Creams. A human would never put this in the list however, because the meaning a reader would infer from the entry is that Canary Creams cost 1000 Galleons. While the passage is “unfair” to the model to some degree, this just goes to show that extracting information from text is a delicate affair, and there are lots of ways it can go wrong.\nThe list continues with many entries, many looking kind of correct, others obviously incorrect, some doubtful. Let’s look at just one more which jumped out to me, “Dumbledore’s arrest” for a single measly Knut. What prompted this response?\njulia&gt; print(snippet(corpus, snippet_ranges[68]))\nre calmly. \n“Yes, shut up, Potter!” barked Fudge, who was still \nogling Dumbledore with a kind of horrified delight. \n“Well, well, well — I came here tonight expecting to \nexpel Potter and instead — ” \n“Instead you get to arrest me,” said Dumbledore, \nsmiling. “It’s like losing a Knut and finding a Galleon, \nisn’t it?” \n“Weasley!” cried Fudge, now positively quivering with \ndelight, “Weasley, have you written it all down, \neverything he’s said, his confession, have you got it?” \n“Yes, sir, I think so, sir!” said Percy eagerly, whose \nnose was splattered with ink from the speed of his\nThis one is kind of impressive in the peculiar way it manages to be wrong. Dumbledore is using a figure of speech here, his arrest being like losing something of small value (a Knut) and gaining something much more valuable instead (a Galleon). So, technically, if his arrest is like losing a Knut, one could translate that as his arrest having the value of 1 Knut (never mind the Galleon gained). Well done, model!\nThe list ends with many items worth 0,0,0. These are all errors given that the prompt asks for things that have value, but some of them are less wrong than others. You can have a look at the JSON linked above if you’re interested in the prompts for each entry."
  },
  {
    "objectID": "pages/2022-10-13-gpt3-harry-potter/index.html#conclusion",
    "href": "pages/2022-10-13-gpt3-harry-potter/index.html#conclusion",
    "title": "Extracting data from Harry Potter with GPT-3",
    "section": "Conclusion",
    "text": "Conclusion\nI didn’t end up making any plots, which had been my initial goal, because it was more fun to play around with the model and try to understand its outputs. The quality of the data is, to say it bluntly, garbage – even though on first glance it’s impressive that the whole pipeline worked so smoothly at all.\nI did actually make attempts at engineering the prompt away from the errors I was seeing, like trying to exclude items of zero value, or returning “nothing” or other placeholder responses if the model wasn’t sufficiently “sure”. This mostly broke the outputs, though, instead of improving the responses.\nHumans also make mistakes, but they mostly do so in predictable or understandable ways. The model, however, sometimes returns sensible results, or complete nonsense, without a means to easily discern those. In practice, I would have to hand check each entry to see if it was correct, saving me essentially no time. The only real time saver for a human in this scenario is the automated extraction of snippets, which is a classic task that dumb computers are good at.\nI don’t really think the prompt left much room for interpretation (for a human), so the question is, if the prompt could be improved somehow, how do we know in which direction to go? This amounts to trial and error, essentially. Just because some test outputs look better with a changed prompt, that doesn’t mean that the model suddenly “understands” better. It just means that the pattern it outputs matches the pattern we expect more, but the reason for that is entirely opaque. You can’t ask the model to “show its work” or “explain its reasoning” (yet).\nTo me, this little excursion proved again what many online discussions of AI language tools like GitHub Copilot already concluded. The output of such models can look convincing on first glance, and by chance, it can be indistinguishable from that of a human. But you cannot know when it will fail, and in what way. It cannot ask for clarification if it is unsure, it cannot mark passages for review or step outside the box of its prompt in any other way. It will just happily output response after response, with the human operator being fully responsible if they continue working with the result. For code generation, it might be valuable to generate “plausible-looking options” for a human to take inspiration from. For the specific task discussed here, even if it’s rather simple, there’s no benefit at all in employing the model. Therefore, I remain very sceptical what the future will bring, especially because of such language models’ ability to output plausible-looking, but completely false output. The models are great at fooling humans into thinking their output is meaningful, because its structure looks correct. But it requires going beyond the structure of the text, and into the meaning, which is the real challenge here. It remains to be seen if even larger models will suddenly cross that gap in the coming years, or if they remain what this one is, a novelty toy that inspires thought, but doesn’t replace it."
  },
  {
    "objectID": "pages/2021-05-20-reading-data-from-web/index.html",
    "href": "pages/2021-05-20-reading-data-from-web/index.html",
    "title": "Reading data from the web with CSV.jl, DataFrames.jl and Chain.jl",
    "section": "",
    "text": "Recently, I had to read in a dataset from Hillenbrand (1995), published as an annotated csv-like file on a website. The dataset describes formant frequencies of several vowel utterances from different speakers. I thought I ended up with a pretty slick implementation showing off some of the tools available in the Julia data science ecosystem.\nHere’s the dataset if you want to look at it. The challenge is simply that it’s a non-standard file format that needs to be massaged into a form ready for CSV reading first. That means there are also no predefined column names and we don’t want to do a lot of work to write all of these out manually, but use the repetitive structure. My goal is always to write as little unnecessary boilerplate code as possible, without using too much unreadable magic.\nHere’s the final code, afterwards I’ll go through the different statements one by one.\nThe versions used were CSV v0.8.4, Chain v0.4.5 and DataFrames v1.1.1 with Julia 1.6.\nusing Chain, DataFrames, CSV, Downloads\n\n@chain \"http://homepages.wmich.edu/~hillenbr/voweldata/bigdata.dat\" begin\n    Downloads.download(IOBuffer())\n    String(take!(_))\n    _[findfirst(\"b01ae\", _)[1]:end]\n    replace(r\" +\" =&gt; \" \")\n    replace(r\"\\s+$\"m =&gt; \"\\n\")\n    CSV.read(IOBuffer(_), DataFrame, header = false,\n        missingstring = \"0\")\n    rename(1:30 .=&gt; [\n        :filename;\n        :duration_msec;\n        Symbol.([\"f0\", \"f1\", \"f2\", \"f3\"], \"_steady\");\n        [Symbol(f, \"_\", p)\n            for p in 10:10:80\n            for f in [\"f1\", \"f2\", \"f3\"]]\n    ])\n    transform(:filename =&gt;\n        ByRow(f -&gt; (\n            type = f[1],\n            number = parse(Int, f[2:3]),\n            vowel = f[4:5]\n        )) =&gt; AsTable)\n    transform(:type =&gt;\n        ByRow(t -&gt; Dict(\n            'm' =&gt; \"man\",\n            'w' =&gt; \"woman\",\n            'b' =&gt; \"boy\",\n            'g' =&gt; \"girl\")[t]) =&gt; :type)\n    select(1:2, 31:33, 3:30)\n    CSV.write(\"hillenbrand.csv\", _)\nend\nOk, let’s look at the parts:\n@chain \"http://homepages.wmich.edu/~hillenbr/voweldata/bigdata.dat\" begin\nFirst, we start a @chain from Chain.jl with the url we want to download. In a chain, we can feed the result from one expression into the first argument of the next, unless we specify a different position with the _ placeholder.\nDownloads.download(IOBuffer())\nString(take!(_))\nWe download the content at the url right into an IOBuffer object, which avoids creating a separate file. The IOBuffer is then converted into a string because we have to clean it up a bit.\n_[findfirst(\"b01ae\", _)[1]:end]\nreplace(r\" +\" =&gt; \" \")\nreplace(r\"\\s+$\"m =&gt; \"\\n\")\nThe first line finds the occurence of the first part of the actual data entries, then selects only the part of the string from there on out. The second line finds all multiple spaces and replaces them with one space, while the third line removes all trailing whitespace before the end of a line. Both of these things can otherwise throw off CSV.jl when it determines how many columns there are.\nCSV.read(IOBuffer(_), DataFrame, header = false,\n    missingstring = \"0\")\nNow we convert the string back to an IOBuffer, so that we can use it directly with CSV.read. Using the string itself doesn’t work, because CSV.jl would assume it’s a file path. We read into a DataFrame and specify that there’s no header, because the file has no column names. We also specify that the string “0” is a missing value, which is the convention of this dataset but which could easily throw off our analyses if we aren’t careful. Using missing values forces us to acknowledge them explicitly in our analysis.\nrename(1:30 .=&gt; [\n    :filename;\n    :duration_msec;\n    Symbol.([\"f0\", \"f1\", \"f2\", \"f3\"], \"_steady\");\n    [Symbol(f, \"_\", p)\n        for p in 10:10:80\n        for f in [\"f1\", \"f2\", \"f3\"]]\n])\nHere we rename the columns in a succinct way, the structure is described in the data file. We broadcast an integer range from 1 to 30, which is the number of columns, with a list of 30 Symbols. The first two we specify manually, then there’s f0_steady, f1_steady, etc. Finally, we need to make 24 column names which go like f1_10, f2_10, f3_10, f1_20, and so on. We can easily do this with a nested list comprehension, where we loop over the percentages in the outer loop, and over the formants in the inner loop.\ntransform(:filename =&gt;\n    ByRow(f -&gt; (\n        type = f[1],\n        number = parse(Int, f[2:3]),\n        vowel = f[4:5]\n    )) =&gt; AsTable)\nThe data file specifies that some information is encoded in the filename. We extract this with a function that operates by row, and extracts the three components into fields of a named tuple. By passing AsTable as the sink, these named tuples are automatically expanded into correctly named columns.\ntransform(:type =&gt;\n    ByRow(t -&gt; Dict(\n        'm' =&gt; \"man\",\n        'w' =&gt; \"woman\",\n        'b' =&gt; \"boy\",\n        'g' =&gt; \"girl\")[t]) =&gt; :type)\nThe type of speaker is currently encoded as a Char, but we can transform this column to a more readable form by looking up the long version of each character in a small dictionary.\nselect(1:2, 31:33, 3:30)\nOur three new columns have been appended at the end, but it would be nicer if the speaker descriptions were more at the front. So we just use a select statement, where the first two columns come first, then the last three, and then the rest.\nCSV.write(\"hillenbrand.csv\", _)\nAs the last step, we write out the cleaned table into a csv file, and we’ve already reached the end of this short tutorial. This is what the end result looks like:\n1668×33 DataFrame\n  Row │ filename  duration_msec  type    number  vowel   f0_steady  f1_steady  f2_steady  f3_steady  f1_10  f2_10   f3_10    f1_20  f2_20   f3_20    f1_30  f2_3 ⋯\n      │ String    Int64          String  Int64   String  Int64      Int64      Int64?     Int64?     Int64  Int64?  Int64?   Int64  Int64?  Int64?   Int64  Int6 ⋯\n──────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n    1 │ b01ae               257  boy          1  ae            238        630       2423       3166    625    2388     3174    651    2413     3115    675    24 ⋯\n    2 │ b02ae               359  boy          2  ae            286        829       2495       3218    802    2392     3625    778    2461     3424    793    24\n    3 │ b03ae               335  boy          3  ae            214        631       2801       3508    631    2801     3508    602    2760     3453    573    28\n    4 │ b04ae               398  boy          4  ae            239        712       2608       3247    729    2604     3239    712    2608     3247    695    25\n    5 │ b05ae               267  boy          5  ae            200        748       2589       3042    728    2601     3047    752    2562     3033    767    25 ⋯\n    6 │ b07ae               323  boy          7  ae            262        769       2203       3126    769    2203     3126    760    2169     3144    813    22\n    7 │ b08ae               316  boy          8  ae            216        870       2281       3077    765    2252     3214    820    2239     3181    864    23\n    8 │ b09ae               245  boy          9  ae            220        709       2565       3526    626    2545     3504    709    2565     3526    663    26\n    9 │ b10ae               396  boy         10  ae            205        634       2555       3121    635    2560     3230    642    2559     3126    633    25 ⋯\n   10 │ b11ae               298  boy         11  ae            209        630       2509       3112    630    2509     3112    627    2513     3098    616    25\n   11 │ b12ae               415  boy         12  ae            252        736       2505       3332    729    2544     3261    736    2504     3307    739    25\n   12 │ b13ae               281  boy         13  ae            216        634       2535       3260    634    2535     3260    630    2532     3248    623    25\n   13 │ b14ae               314  boy         14  ae            198        697       2418       3371    681    2444     3430    657    2471     3376    697    24 ⋯\n   14 │ b15ae               382  boy         15  ae            272        607       2620       3350    607    2620     3350    617    2599     3369    628    25\n   15 │ b16ae               367  boy         16  ae            187        753       2227       3064    788    2244     3150    750    2233     3042    749    22\n   16 │ b17ae               352  boy         17  ae            246        726       2231       2932    726    2231     2932    742    2246     2902    745    22\n   17 │ b18ae               307  boy         18  ae            249        741       2444       3043    735    2446     3008    746    2455     3021    748    24 ⋯\n   18 │ b19ae               312  boy         19  ae            209        674       2663       3243    684    2665     3268    693    2672     3256    733    26\n   19 │ b21ae               352  boy         21  ae            205        769       2234       2910    766    2245     2917    771    2215     2889    771    21\n   20 │ b22ae               256  boy         22  ae            229        678       2524       3418    687    2580     3288    678    2501     3424    677    25\nAs always, there are lots of ways of achieving the same thing. This is just one version that I was satisfied with, and I hope you have learned one or two new techniques that can be useful to you in the future."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "",
    "text": "If you’re new to Julia, here is a scenario that might have tripped you up already: Let’s define two points. Both are just a collection of two floating point numbers. But one is a Vector, written with the [] syntax, and one a Tuple, written with the () syntax. Then we make vectors of both types of points and run a short computation. Let’s see what the performance difference looks like.\nThe Vector version is much slower than the Tuple version. But why? Are Vectors bad and Tuples good?\nIn the following post I’ll try to explain in simple terms why we see such a big difference and how you can use your new knowledge to write better code in Julia."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#allocations",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#allocations",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Allocations",
    "text": "Allocations\nThe @time outputs show that there were 250,000 allocations for the vector version and only 2 for the tuple version. What does that mean and why does it make the code slow?\nAn allocation is a request for memory. Our program tells the operating system “I need space to store some values” and the operating system gives back the location of some empty space in our RAM we can use.\nAsking the operating system for memory takes time, therefore more allocations make our code slower. So far, so good.\nIn the vector case, this happened 250,000 times, or once for each entry in the 500 x 500 distance matrix. In the tuple code it happened only twice.\nBut isn’t that weird?\nIn both cases, each point consists of two floating point numbers. Each computation generates the exact same number of points. So why do we need to ask for more memory in the vector version?\nThis leads us to the next important piece of the puzzle: We need to look at what the stack and the heap are."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#stack-and-heap",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#stack-and-heap",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Stack And Heap",
    "text": "Stack And Heap\nMany programming languages work with two concepts called the stack and the heap. These concepts are just two different ways of organizing memory, which influence the speed with which programs run.\nThe heap is comparable to a big space where stored objects are scattered all over the place. Some objects are big, some are small, and there may be large or small gaps between them. The heap is a bit messy, but it is also spacious. If you want to store a new object there, the operating system finds a suitable location for you and gives you the address.\nThe stack on the other hand has a very strict order. It’s like a tower of objects which are stacked neatly in memory, one on top of the other. There are no gaps between them, and you can’t just pull out objects from the middle. You can only take off the topmost object or stack new ones on top of that one. New objects are always stored on top, never anywhere else.\nWhy do we have the two kinds?\nThe heap is for all objects that can dynamically change in size and for objects that should live longer in memory. If you need more or less space for some object which is on the heap, you can maybe expand it into some empty space around it, or you have to find a new place and copy it there. The stack on the other hand can only be built out of objects that never change in size. Imagine how that neat tower would react if an object right in the middle suddenly shrank or expanded?\nThat’s not allowed.\nThis might seem restrictive, but on the other hand it makes the stack really fast. Our program always knows where each object in the stack is and what size it has. We also never need to ask the operating system for additional memory when storing things on the stack. That’s because we have preallocated memory for it that should be enough for almost all purposes (as long as we don’t just keep stacking on top without removing things in between, then you get one of the famed stack overflows).\nTo sum up, using stack memory is much faster than allocating on the heap. The problem is that not every object can be stored on the stack, only those that never change in size can be.\nHow does that relate to our Vectors and Tuples? It’s simple: Vectors are mutable and Tuples are not."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#mutable-and-immutable-objects",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#mutable-and-immutable-objects",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Mutable And Immutable Objects",
    "text": "Mutable And Immutable Objects\nAt first glance, the two descriptions of a point [rand(), rand()] and (rand(), rand()) might look really similar, and obviously we could run the same function with both versions. The difference is that the Vector created with [] is mutable, and the Tuple created with () is immutable.\nFor example this works:\nvector_point = [1.0, 2.0]\npush!(vector_point, 3.0)\n3-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\nAnd this doesn’t:\ntuple_point = (1.0, 2.0)\npush!(tuple_point, 3.0)\nERROR: MethodError: no method matching push!(::Tuple{Float64,Float64}, ::Float64)\nAnother important difference is the exact type of each object. The vector point is of type Array{Float64,1}, or a one-dimensional array of Float64s. The tuple point is of type Tuple{Float64,Float64}, or a tuple of exactly two Float64s.\nNotice the difference? The tuple type guarantees that there are always exactly two elements in our point. The Array{Float64,1} makes no such guarantee.\nIn Julia, a generic function has a method compiled for each combination of specific types of input arguments that we give it. So the method of difference_matrix(points) where points is a Vector of points of type Array{Float64,1} doesn’t know how many elements such points have, or how much memory will be needed for the resulting points, or even the matrix storing these points. That all has to be determined dynamically. Dynamic is slow!\nWhen the compiler compiles the method of difference_matrix(points) that uses points of type Tuple{Float64, Float64}, it has so much more information. It knows that each point has a specific width in memory. It knows that for each subtraction operation, the exact same size will be needed on the stack. It also knows that the resulting Matrix of points can be stored contiguously in memory.\nContiguous means packed tightly together. We can do that with the tuple points because again we know their size beforehand. With the vector points, we don’t know that. The matrix that stores our vector points actually only stores the addresses for each of the little mutable point vectors. These vectors are then scattered all over the heap, with no guaranteed order that the computer could make use of. This should strike you as a really messy way of dealing with a simple matrix of points, and you would be right. The array of tuples where all points are packed together like sardines is much better.\nNotice that the matrix of tuples itself is not stored on the stack, but is stored in contiguous fashion on the heap. As long as we only need one allocation for that big piece of memory, that cost disappears compared to the computations we do with that memory. The 250,000 allocations in the vector case come from each individual Vector that results from the subtraction of two existing Vectors. For the matrix that stores the addresses of those individual vectors we again need only one allocation, because the memory addresses of mutable objects are themselves immutable objects of fixed size…"
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#its-not-just-tuples",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#its-not-just-tuples",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "It’s Not Just Tuples",
    "text": "It’s Not Just Tuples\nThe mechanism explained above is not specific to tuples. It works with basically every immutable data structure that has a fixed size in memory given its type. For example, we could define a point as an immutable struct containing exactly two Float64s and would enjoy similar benefits:\nstruct Point\n    x::Float64\n    y::Float64\nend\nActually, such a point would have the exact same memory footprint as a Tuple{Float64,Float64} and the compiler might even treat them exactly the same on a machine code level.\nThe important thing is that the type of our point gives the compiler complete information about the size in memory. Often, the compiler depends on knowing the exact type of objects that are stored in a collection. And it’s not immediately better just because that type is a Tuple.\nFor example, you can store points of type Tuple{Float64, Float64} in a vector with parametric type Tuple{Any,Any}. This basically hides the true identity of our points from the compiler and results in abysmal performance:\nanytuple_points  = Tuple{Any,Any}[rand_tuple_point()  for _ in 1:500]\n\nprintln(\"We have hidden our points in an $(typeof(anytuple_points))\")\n\ndifference_matrix(anytuple_points)\n\nprintln(\"AnyTuple version:\")\n@time difference_matrix(anytuple_points)\nWe have hidden our points in an Array{Tuple{Any,Any},1}\nAnyTuple version:\n  0.109928 seconds (1.75 M allocations: 68.680 MiB, 8.43% gc time)\nThe instructions the compiler created for Tuple{Any,Any} points are much more bloated, because who knows what those tuples contain? Could it be Float64s by chance? The issue above actually leads to a very important concept in Julia called type stability which is another huge factor influencing performance, but is too much for this post."
  },
  {
    "objectID": "pages/2020-10-31-tuples-and-vectors/index.html#stack-those-immutables",
    "href": "pages/2020-10-31-tuples-and-vectors/index.html#stack-those-immutables",
    "title": "Tuples and Vectors, Allocations and Performance for Beginners",
    "section": "Stack Those Immutables",
    "text": "Stack Those Immutables\nTo conclude this introduction, always check that your types are as concrete as possible, that your data structures can be represented by pure bit patterns and stored on the stack if possible. The function isbits helps to figure out if your objects have those desired properties. For example, isbits([1, 2]) == false but isbits((1, 2)) == true.\nYou might never really have encountered immutable data structures if you come from languages like R or Matlab, but they are a big reason why Julia code can be so much faster, so make use of them! If you deal with data structures of known size, preferably use tuples or immutable structs (or check out StaticArrays.jl, which has tuples dressed up as arrays for convenience).\nYou’ll make your compiler’s and therefore your computer’s job much easier, and end up with more efficient and fast code in the process.\nThis is also not nearly all there is to say about the difference between Tuples and Vectors, but it should hopefully get some of the biggest misconceptions out of the way!"
  },
  {
    "objectID": "pages/2021-06-20-football-data-analysis/index.html",
    "href": "pages/2021-06-20-football-data-analysis/index.html",
    "title": "Analyzing international football results with Julia",
    "section": "",
    "text": "As the UEFA Euro 202(0/1) is going on, I was inspired to check out a dataset of all international men’s football matches since the dawn of time. This post goes over some questions I had for the dataset, and how I approached the analysis with my recent macro package DataFrameMacros.jl. Plotting is done with AlgebraOfGraphics.jl, which is a super useful grammar-of-graphics style package building on Makie.jl, which I’m a co-author of and which is therefore my preferred plotting package.\nLet’s set up some basics and import the necessary packages:\n\nusing CairoMakie\nusing AlgebraOfGraphics\nusing Chain\nusing CSV\nusing Downloads\nusing DataFrames\nusing DataFrameMacros\nusing StatsBase\nusing Dates\n\nCairoMakie.activate!(type = \"svg\")\nset_theme!(theme_minimal())\n\nFirst, we need to download the dataset, which is available on github.\n\nurl = \"https://raw.githubusercontent.com/martj42/international_results/master/results.csv\"\n\ndf = @chain url begin\n    Downloads.download\n    CSV.File(missingstring = \"NA\")\n    DataFrame\nend\n\nfirst(df, 10)\n\n\n10 rows × 9 columns (omitted printing of 2 columns)\n\n\n\n\ndate\nhome_team\naway_team\nhome_score\naway_score\ntournament\ncity\n\n\n\nDate\nString\nString\nInt64\nInt64\nString\nString31\n\n\n\n\n1\n1872-11-30\nScotland\nEngland\n0\n0\nFriendly\nGlasgow\n\n\n2\n1873-03-08\nEngland\nScotland\n4\n2\nFriendly\nLondon\n\n\n3\n1874-03-07\nScotland\nEngland\n2\n1\nFriendly\nGlasgow\n\n\n4\n1875-03-06\nEngland\nScotland\n2\n2\nFriendly\nLondon\n\n\n5\n1876-03-04\nScotland\nEngland\n3\n0\nFriendly\nGlasgow\n\n\n6\n1876-03-25\nScotland\nWales\n4\n0\nFriendly\nGlasgow\n\n\n7\n1877-03-03\nEngland\nScotland\n1\n3\nFriendly\nLondon\n\n\n8\n1877-03-05\nWales\nScotland\n0\n2\nFriendly\nWrexham\n\n\n9\n1878-03-02\nScotland\nEngland\n7\n2\nFriendly\nGlasgow\n\n\n10\n1878-03-23\nScotland\nWales\n9\n0\nFriendly\nGlasgow\n\n\n\n\n\n\n\nLet’s start with a simple question: How did the number of games played per year develop over time? In DataFrameMacros.jl, you can group by columns that you create directly in the groupby call.\nWe can directly visualize the result by chaining the analysis into AlgebraOfGraphics.\n\n@chain df begin\n    @groupby(:year = year(:date))\n    combine(nrow =&gt; :n_games)\n    data(_) *\n        mapping(:year =&gt; \"Year\", :n_games =&gt; \"Number of games\") *\n        visual(Scatter)\n    draw\nend\n\n\n\n\n\n\n\n\nThere has been a huge growth in the number of games per year. What could have been the driving factors there? We could look at the development of friendly vs. non-friendly games.\nAs soon as there are some groups to plot separately, I like using AlgebraOfGraphics.jl, which does all the work of grouping and legend building for me. I can build one long chain that culminates in a plot, so I don’t have to come up with names for intermediary steps.\n\n@chain df begin\n    @groupby(:year = year(:date), :friendly = :tournament == \"Friendly\")\n    combine(nrow =&gt; :n_games)\n    data(_) *\n        mapping(:year =&gt; \"Year\", :n_games =&gt; \"Number of games\",\n            color = :friendly =&gt; nonnumeric) *\n        visual(Scatter)\n    draw\nend\n\n\n\n\n\n\n\n\nSo we can see that both friendlies and competitions have become much more numerous, although the competitions are responsible for the larger share.\nAnother way we could look at this information is to count the number of different competitions per year:\n\n@chain df begin\n    @subset(:tournament != \"Friendly\")\n    @groupby(:year = year(:date))\n    @combine(:n_competitions = length(unique(:tournament)))\n    data(_) *\n        mapping(:year =&gt; \"Year\", :n_competitions =&gt; \"Number of competitions\") *\n        (visual(Scatter, markersize = 5) + smooth())\n    draw\nend\n\n\n\n\n\n\n\n\nAnd of course the average number of teams per competition:\n\n@chain df begin\n    @subset(:tournament != \"Friendly\")\n    @groupby(:year = year(:date), :tournament)\n    @combine(:n_teams = @c length(unique(vcat(:home_team, :away_team))))\n    data(_) *\n        mapping(:year =&gt; \"Year\", :n_teams =&gt; \"Number of teams per competition\") *\n        (visual(Scatter, markersize = 4, color = (:black, 0.3)) + smooth() * visual(linewidth = 3))\n    draw\nend\n\n\n\n\n\n\n\n\nSo both the number of competitions, as well as the number of teams taking part in each competition has increased over the years.\nLet’s check out how the number of goals per game during world cups has developed over time. As football has become more and more professionalized, do the highly trained players of today score more or fewer goals? (The defense is also better trained, of course.)\n\n@chain df begin\n    @subset(:tournament == \"FIFA World Cup\")\n    @transform(:year = year(:date))\n    @transform(:n_goals = :home_score + :away_score)\n    @groupby(:year)\n    @combine(:average_goals = mean(:n_goals))\n    data(_) *\n        mapping(:year =&gt; \"Year\", :average_goals =&gt; \"Average goals per game\") *\n        (visual(Scatter) + smooth())\n    draw(axis = (limits = (nothing, (0, nothing)),))\nend\n\n\n\n\n\n\n\n\nIt seems the number of goals has gone down over time, from around 4 to 2.5 or so, where it has plateaued. This dataset can give no indication, though, what the reasons for this development might be.\nOne thing we can look at, though, is the distribution of goal differences over time. Maybe the teams were just much more different in ability before?\nWe could make histograms for 1954 and 1990, which had high and low averages, respectively.\n\n@chain df begin\n    @transform(:year = year(:date))\n    @subset(:tournament == \"FIFA World Cup\", :year in (1954, 1990))\n    @transform(:goal_difference = abs(:home_score - :away_score))\n    data(_) *\n        mapping(:goal_difference  =&gt; \"Goal difference\",\n            col = :year =&gt; nonnumeric) *\n        frequency()\n    draw\nend\n\n\n\n\n\n\n\n\nSo there were even games with 7 or 9 goals difference in 1954, suggesting that at least some of the matches might have been quite unbalanced at the time, driving a higher goal average.\nIn 1990, most games were decided by one goal difference, in comparison.\nLet’s turn to another question, that of the home team advantage. For a quick glance, we can compute the probability of winning as the home team.\n\n@chain df begin\n    @subset(_, !:neutral; skipmissing = true)\n    @transform(:home_result = @m :home_score &gt; :away_score ?\n        \"win\" : :away_score &gt; :home_score ? \"lose\" : \"tie\")\n    dropmissing(:home_result)\n    @aside n = nrow(_)\n    @groupby(:home_result)\n    @combine(:p = length(:home_result) / n)\nend\n\n\n3 rows × 2 columns\n\n\n\n\nhome_result\np\n\n\n\nString\nFloat64\n\n\n\n\n1\ntie\n0.231335\n\n\n2\nwin\n0.505947\n\n\n3\nlose\n0.262718\n\n\n\n\n\n\n\nIt looks like the probability to win as the home team is about 50%, so twice as likely as losing. This could be a bit misleading, potentially, if the better teams are also somehow the teams that host more games.\nSo we could check how it looks if we compute the win lose ratio for each team separately. One problem is that each “team” (country) changes all the time, and Germany from 1950 has nothing in common with Germany from 2020. As an approximation, we can split the timeline into 5 year bins, and calculate the ratio within those.\n\n@chain df begin\n    @subset(_, !:neutral; skipmissing = true)\n    @transform(:home_result = @m :home_score &gt; :away_score ?\n        \"win\" : :away_score &gt; :home_score ? \"lose\" : \"tie\")\n    dropmissing(:home_result)\n    @transform(:fiveyears = year(:date) - year(:date) % 5)\n    stack([:home_team, :away_team], variable_name = :type,\n        value_name = :team)\n    @transform(:result = if :type == \"home_team\"\n        :home_result\n    else\n        :home_result == \"win\" ? \"lose\" :\n            :home_result == \"lose\" ? \"win\" : \"tie\"\n    end)\n    @subset(:result != \"tie\")\n    @groupby(:fiveyears, :team, :type, :result)\n    combine(nrow  =&gt; :count)\n    unstack(:result, :count)\n    @transform(:win = coalesce(:win, 0), :lose = coalesce(:lose, 0))\n    @transform(:p_win = :win / (:win + :lose))\n    unstack([:fiveyears, :team], :type, :p_win)\n    @transform(:home_p_win_delta = :home_team - :away_team)\n    dropmissing(:home_p_win_delta)\n    data(_) *\n        mapping(:fiveyears =&gt; \"Five year period\", :home_p_win_delta =&gt; \"p(win) - p(lose)\") *\n        (visual(Scatter, markersize = 5, color = (:black, 0.2)) + smooth())\n    draw\nend\n\n\n\n\n\n\n\n\nEven though this is only a pretty rough analysis, the home advantage appears to hold up when looking at it within each team, separately over time.\nThis was an example of data analysis and plotting with DataFrameMacros.jl and AlgebraOfGraphics.jl. I hope you learned something new, either about Julia, or about international football."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html",
    "href": "pages/2021-06-07-macros-for-beginners/index.html",
    "title": "Julia macros for beginners",
    "section": "",
    "text": "Macros are a powerful and interesting feature of the Julia programming language, but they can also be confusing. Users coming from Python, Matlab or R have not come in contact with similar constructs before, and they require a different way of thinking about code. This article is supposed to be a simple introduction, after which you might judge better when use of macros is appropriate and how to get around some of the most common gotchas."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#what-are-macros-for",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#what-are-macros-for",
    "title": "Julia macros for beginners",
    "section": "What are macros for?",
    "text": "What are macros for?\nMacros change existing source code or generate entirely new code. They are not some kind of more powerful function that unlocks secret abilities of Julia, they are just a way to automatically write code that you could have written out by hand anyway. There’s just the question whether writing that code by hand is practical, not if it’s possible. Often, we can save users a lot of work, by hiding boilerplate code they would otherwise need to write inside our macro.\nStill, it’s good advice, especially for beginners, to think hard if macros are the right tool for the job, or if run-of-the-mill functions serve the same purpose. Often, functions are preferable because macro magic puts a cognitive burden on the user, it makes it harder to reason about what code does. Before understanding the code, they have to understand the transformation that the macro is doing, which often goes hand in hand with non-standard syntax. That is, unless they are ok with their code having unintended consequences."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#what-does-a-macro-do",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#what-does-a-macro-do",
    "title": "Julia macros for beginners",
    "section": "What does a macro do?",
    "text": "What does a macro do?\nSome of the magic of macros derives from the fact that they don’t just generate some predefined code, they rather take the code they are applied to and transform it in useful ways. Variable names are one of the fundamental mechanisms by which we make code understandable for humans. In principle, you could replace every identifier in a working piece of code with something random, and it would still work.\nprofit = revenue - costs\n# does the same thing as\nhey = whats - up\nThe computer doesn’t care about the names, only humans do. But functions run after the code has been transformed into lower-level representations, and names are lost at that point.\nFor example, in this code snippet, there is no way for the author of the function to know what the user named their variable. The function just receives a value, and as far as it is concerned, that value is named x.\n\nfunction show_value(x)\n    println(\"The value you passed is \", x)\nend\n\norange = \"sweet\"\napple = \"sour\"\n\nshow_value(orange)\nshow_value(apple)\n\nThe value you passed is sweet\nThe value you passed is sour\n\n\nAny information about what the user wrote is lost, as the function only knows “sweet” and “sour” were passed. If we want to incorporate the information contained in the variable names, we need a macro.\n\nmacro show_value(variable)\n    quote\n        println(\"The \", $(string(variable)), \" you passed is \", $(esc(variable)))\n    end\nend\n\n@show_value(orange)\n@show_value(apple)\n\nThe orange you passed is sweet\nThe apple you passed is sour\n\n\nYou probably know a macro that works very similar to this one, which is @show\n\n@show orange\n@show apple\n\nNote that it doesn’t make a difference here if we use parentheses for the macros or not. That’s a feature of Julia’s syntax which makes some macros more tidy to write. This is especially true if the macro precedes a for block or some other multi-line expression."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#how-do-macros-work",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#how-do-macros-work",
    "title": "Julia macros for beginners",
    "section": "How do macros work?",
    "text": "How do macros work?\nLet’s look at our macro in more detail. Even though it’s short, it has a few interesting aspects to it.\nFirst of all, a macro runs before any code is executed. Therefore, you never have access to any runtime values in a macro. That’s something that trips many beginners up, but is crucial to understand. All the logic in the macro has to happen only using the information you can get from the expressions that the macro is applied to.\nOne good step to understand what’s going on with an expression, is to dump it. You can use Meta.@dump for that.\nIn our case, it’s not very interesting:\n\nMeta.@dump orange\n\nSymbol orange\n\n\nAs you can see, the expression orange contains only the Symbol orange. So that is what our macro gets as input, just :orange. But, again, no runtime information about it being \"sweet\".\nInside the macro, a quote expression is constructed. A quote with source code inside returns an expression object that describes this code. The expression we return from a macro is spliced into the place where the macro call happens, as if you really had written the macro result there. That’s the reason why a macro can’t technically do more than any old Julia code.\nWe can see the code that the macro call results in by using another helper macro, @macroexpand.\n\n@macroexpand @show_value orange\n\n\nquote\n    #= In[3]:3 =#\n    Main.println(\"The \", \"orange\", \" you passed is \", orange)\nend\n\n\n\nYou can see that, ignoring linenumber and module information, the macro created a function call as if we had written\nprintln(\"The \", \"orange\", \" you passed is \", orange)\nTherefore, let’s look at where the two oranges come from.\nThe first one is \"orange\", which is a string literal. We achieved this with this expression inside the macro:\n$(string(variable))\nRemember that variable holds the Symbol :orange when the macro is called. We convert that to a string and then place that string into the quoted expression using the interpolation symbol $. This is how we can print out a sentence that references the user’s chosen variable name.\nThe other orange is just a normal variable name. It was created with the interpolation expression $(esc(variable)). The esc stands for escape and is another part of macros that is hard to understand for beginners."
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#whats-escaping",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#whats-escaping",
    "title": "Julia macros for beginners",
    "section": "What’s escaping?",
    "text": "What’s escaping?\nTo explain why esc is needed, let’s look at a macro that leaves it out. In this example we define the macro in a separate module (because any macro you’d put in a package would not be in the Main module either):\n\nmodule SomeModule\n    export @show_value_no_esc\n    macro show_value_no_esc(variable)\n        quote\n            println(\"The \", $(string(variable)), \" you passed is \", $variable)\n        end\n    end\nend\n\nusing .SomeModule\n\ntry\n    @show_value_no_esc(orange)\ncatch e\n    sprint(showerror, e)\nend\n\n\"UndefVarError: `orange` not defined\"\n\n\nThe code errors because there is no variable orange. But there should be, we interpolated it right there! Let’s look at the macro output with @macroexpand again:\n\n@macroexpand @show_value_no_esc(orange)\n\n\nquote\n    #= In[7]:5 =#\n    Main.SomeModule.println(\"The \", \"orange\", \" you passed is \", Main.SomeModule.orange)\nend\n\n\n\nOk, so the variable looked up is actually SomeModule.orange, and of course we didn’t define a variable with that name in SomeModule. The reason this happens is that macros do often need to reference values from whatever module they were defined in (for example, to add a helper function, that also lives in that module, to the user’s code). Any variable name used in the created expression is looked up in the macro’s parent module by default.\nThe other reason is that it is potentially dangerous to just change or create variables in user space in a macro that knows nothing about what’s going on there.\nImagine the writer of the macro and the user as two people who know nothing about each other. They only interface via the small snippet of code passed to the macro. So, obviously, the macro shouldn’t mess around with the user’s variables.\nIn theory, a macro could insert things like my_variable = nothing or empty!(some_array) in the place where it’s used. But imagine the user already has a my_variable and it happens to hold the result of a computation that ran hours. As the macro writer doesn’t know anything about the variables the user has created, all macro-created variables are by default scoped to the macro’s module to avoid conflicts.\nHere’s a short example of bad escaping, with a macro that is not really supposed to do anything:\n\nmacro change_nothing(exp)\n    e = quote\n        temp_variable = nothing # this could be some intermediate computation\n        $exp # we actually just pass the input expression back unchanged\n    end\n    esc(e) # but everything is escaped\nend\n\n@change_nothing (macro with 1 method)"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#a-user-who-happens-to-have-a-temp-variable-calls-this-macro",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#a-user-who-happens-to-have-a-temp-variable-calls-this-macro",
    "title": "Julia macros for beginners",
    "section": "a user who happens to have a temp variable calls this macro…",
    "text": "a user who happens to have a temp variable calls this macro…\n\ntemp_variable = \"important information\"\nx = @change_nothing 1 + 1\n\n@show x\n@show temp_variable\n\nWhoops, the temp_variable was overwritten by the macro, and this can happen with badly written macros.\nBut still, in order to access the value of the user’s variable orange, we need to escape the use of that symbol in our generated expression. Escaping the variable could be summarized as saying “treat this variable like a variable the user has written themselves”.\nAs a rule of thumb, macros should only ever escape variables that they know about because they were passed to the macro. These are the variables that the user potentially wants to have changed by the macro, or at least they are aware that they could be subject to change.\nHere you can see another example, where there is both a user and a module orange:\n\nmodule AnotherModule\n    export @show_value_user_and_module\n\n    orange = \"bitter\"\n\n    macro show_value_user_and_module(variable)\n        quote\n            println(\"The \", $(string(variable)), \" you passed is \", $(esc(variable)),\n                \" and the one from the module is \", $variable)\n        end\n    end\nend\n\nusing .AnotherModule\n\n@show_value_user_and_module orange\n\nThe orange you passed is sweet and the one from the module is bitter"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#modifying-expressions",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#modifying-expressions",
    "title": "Julia macros for beginners",
    "section": "Modifying expressions",
    "text": "Modifying expressions\nEven though we could already see some interesting macro properties, maybe you didn’t start reading this article to learn about printing users their own variable names back (even though that is a very user friendly behavior in general, and many R users like their non-standard evaluation a lot for this reason).\nUsually, you want to modify the expression you receive, or build a new one with it, to achieve some functional purpose. Sometimes, macros are used to define domain specific languages or DSLs, that allow users to specify complex things with simple, yet non-standard expressions.\nA good example for this are the formulas from StatsModels.jl, where @formula(y ~ x) is a nice shortcut to create a formula object that you could in principle build yourself without a macro, but with much more typing.\nLet’s try to write a small useful macro that transforms a real expression!\nAn issue some Julia users face once in a while is that the fill function’s argument is executed once, and then the whole vector is filled with that result. Let’s say we want a vector of 5 three-element random vectors.\n\nrand_vec = fill(rand(3), 5)\n\n5-element Vector{Vector{Float64}}:\n [0.9039841821218482, 0.3644507708511703, 0.8407975367191795]\n [0.9039841821218482, 0.3644507708511703, 0.8407975367191795]\n [0.9039841821218482, 0.3644507708511703, 0.8407975367191795]\n [0.9039841821218482, 0.3644507708511703, 0.8407975367191795]\n [0.9039841821218482, 0.3644507708511703, 0.8407975367191795]\n\n\nAs you can see, every vector is the same, which we don’t want. A way to get our desired result is with a list comprehension:\n\nrand_vec = [rand(3) for _ in 1:5]\n\n5-element Vector{Vector{Float64}}:\n [0.8957367680265885, 0.249510539903665, 0.8937505345144938]\n [0.9314953138974689, 0.25762719951419766, 0.15016666804238443]\n [0.27431927403854617, 0.16696200453179322, 0.18711308743600819]\n [0.15334416897527525, 0.09403493703533272, 0.9900757734923491]\n [0.520051568171863, 0.06984731462064464, 0.5529582754578751]\n\n\nThis works, but the fill syntax is so nice and short in comparison. Also it gets even worse if you are iterating multiple dimensions in nested for loops, while you can always write fill(rand(3), 3, 4, 5).\nSo can we write a macro that makes a list comprehension expression out of a call like @fill(rand(3), 5), so that the first argument is executed anew in each iteration? Let’s try it!\nThe first step is always to understand what expression you’re even trying to build. We already use two iterators here to understand how multiple are handled in the resulting expression:\n\nMeta.@dump [rand(3) for _ in 1:5, _ in 1:3]\n\nExpr\n  head: Symbol comprehension\n  args: Array{Any}((1,))\n    1: Expr\n      head: Symbol generator\n      args: Array{Any}((3,))\n        1: Expr\n          head: Symbol call\n          args: Array{Any}((2,))\n            1: Symbol rand\n            2: Int64 3\n        2: Expr\n          head: Symbol =\n          args: Array{Any}((2,))\n            1: Symbol _\n            2: Expr\n              head: Symbol call\n              args: Array{Any}((3,))\n                1: Symbol :\n                2: Int64 1\n                3: Int64 5\n        3: Expr\n          head: Symbol =\n          args: Array{Any}((2,))\n            1: Symbol _\n            2: Expr\n              head: Symbol call\n              args: Array{Any}((3,))\n                1: Symbol :\n                2: Int64 1\n                3: Int64 3\n\n\nAha, now we actually see some real expressions. Every Expr object has a head that stores what kind of expression it is, and a vector called args which contains all arguments to that expression.\nWe can see that a list comprehension is made by making an Expr where the head is :comprehension. There’s only one argument to that expression, which is a :generator expression. This one in turn is assembled of the expression being called in each iteration, and the iteration expressions _ = 1:5 and _ = 1:3.\nWe want to use the syntax @fill(rand(3), sizes...), so we need to think how we can transform those two arguments into the expression we want.\nHere, we’ll build the Expr by hand, instead of writing one big quote. Sometimes that is easier, it also depends on what you find more readable. Expressions with a lot of quoting and interpolating can be hard to understand. I usually prefer quote ... end over the equivalent :(...) just because I can parse words a bit better than parentheses.\nHere we go:\nFor each size argument, we make one of the iterator expressions that we saw in the dump above. We escape each size variable s because those are the arguments that the user will write themselves, and they need to resolve correctly in their scope later.\nThe comprehension expression then receives the first argument escaped because that expression also needs to run as-is in the user’s scope.\n\nmacro fill(exp, sizes...)\n   \n    iterator_expressions = map(sizes) do s\n        Expr(\n            :(=),\n            :_,\n            quote 1:$(esc(s)) end\n        )\n    end\n    \n    Expr(\n        :comprehension,\n        esc(exp),\n        iterator_expressions...\n    )\nend\n\n@fill (macro with 1 method)\n\n\nLet’s try it out:\n\n@fill(rand(3), 5)\n\n5-element Vector{Vector{Float64}}:\n [0.23155776289714214, 0.16506850108672544, 0.6975576110978176]\n [0.9321190744533363, 0.7284798945126126, 0.8736131864599121]\n [0.36504661751333844, 0.022691708746904182, 0.5288865087865801]\n [0.8521086358547397, 0.2895922988729154, 0.1456070184114313]\n [0.8720484237531486, 0.21008612789745829, 0.5082683499697537]\n\n\nA good check if you’ve escaped correctly is to pass expressions that reference some local variables. The call will error if you’ve forgotten to escape any of them:\n\nn = 3\nk = 5\n\n@fill(rand(n), k)\n\n5-element Vector{Vector{Float64}}:\n [0.5917157732709782, 0.8755225218366083, 0.4032454673315716]\n [0.6111142681907994, 0.06564154230386965, 0.4591276163618556]\n [0.6521749060007972, 0.26064420556063617, 0.2085548309582519]\n [0.64546352947466, 0.485066158128166, 0.20739815115743743]\n [0.8058584624008102, 0.9168621696136154, 0.4280967575910163]\n\n\nThis works fine! It should also work with more size arguments, we’ll generate only random scalars so the printout is manageable:\n\n@fill(rand(), 5, 3)\n\n5×3 Matrix{Float64}:\n 0.144371   0.952823    0.331021\n 0.289901   0.00354794  0.822716\n 0.233857   0.810845    0.933876\n 0.665742   0.988701    0.133996\n 0.0806734  0.270098    0.825293\n\n\nEven though this particular example is contrived for simplicity (we could just use rand(5, 3 of course) compare it to the alternative list comprehension syntax:\n\n[rand() for _ in 1:5, _ in 1:3]\n\n5×3 Matrix{Float64}:\n 0.603045   0.63075   0.313092\n 0.624411   0.835403  0.194775\n 0.924256   0.944286  0.145364\n 0.541554   0.571108  0.120784\n 0.0716549  0.75666   0.619488"
  },
  {
    "objectID": "pages/2021-06-07-macros-for-beginners/index.html#summary",
    "href": "pages/2021-06-07-macros-for-beginners/index.html#summary",
    "title": "Julia macros for beginners",
    "section": "Summary",
    "text": "Summary\nAs you can see, macros can be a gain in syntax clarity, and they offer a powerful way to interact with the user’s source code.\nJust remember that a reader also needs to understand what’s happening. In our example, rand() is not just executed once but many times, which is non-standard behavior for something resembling a function call. This code-reasoning overhead must always be weighed against the convenience of shorter syntax.\nI hope you have learned a thing or two about macros and are encouraged to play around with them yourself. Usually, good ideas for macros only present themselves after interacting with Julia for a while, so if you are a beginner, give it time and become proficient with normal functions first."
  },
  {
    "objectID": "pages/2024-05-03-makie-logo/index.html",
    "href": "pages/2024-05-03-makie-logo/index.html",
    "title": "Recreating the Makie logo with Luxor.jl",
    "section": "",
    "text": "This is the logo of Makie.jl:\n\nI designed it by hand in a vector graphics editor a couple years ago, however, I always wanted to have a programmatic version of it.\nFirst of all, because with a program it’s easier to make variations of it or play with it, for example to make animations. The other reason was that the original vector graphics file always seemed a bit large for what it was, at 118KB. The gradient mesh from the editor is flattened to a relatively large inline image for SVG, because SVG doesn’t support meshes. I wanted to have a programmatic version where I could make this image as small as possible while still looking good.\nI decided to make it with Luxor.jl because it’s a relatively thin wrapper around Cairo and nicely documented.\n\nusing Luxor\nusing Colors\nusing LinearAlgebra\n\nThe basic structure of the logo is a simple cube consisting of three diamonds because Makie is a 3D visualization package.\n\n@drawsvg begin\n    scale(150, -150)\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.((p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        move(p1)\n        line(p2)\n        line(p3)\n        line(p4)\n        closepath()\n        strokepath()\n    end\nend 400 400\n\n\n\n\n\n\n\n\nNext, we move each diamond outwards, which gives the cube an “exploded” look.\n\n@drawsvg begin\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        move(p1)\n        line(p2)\n        line(p3)\n        line(p4)\n        closepath()\n        strokepath()\n    end\nend 400 400\n\n\n\n\n\n\n\n\nNow we have to round the corners of the diamonds to make them more petal-like (the petals are a reference to the floral patterns sometimes seen with the Maki-e painting technique).\nTo get rounded corners, we need a function which takes in three points that form the sharp corner plus a radius, and calculates where the circular arc with that radius is connected to the adjacent line segments.\n\nfunction rounded_corner(p1, p2, p3, radius)\n    d1 = p2 - p1\n    d1_ortho = normalize(Point(-d1.y, d1.x))\n    d2 = p3 - p2\n    d2_ortho = normalize(Point(-d2.y, d2.x))\n\n    _, circle_center = Luxor.intersectionlines(\n        p1 + radius * d1_ortho,\n        p2 + radius * d1_ortho,\n        p2 + radius * d2_ortho,\n        p3 + radius * d2_ortho,\n    )\n\n    circle_center\n    start = circle_center - radius * d1_ortho\n    stop = circle_center - radius * d2_ortho\n\n    circle_center, start, stop\n    arc2r(circle_center, start, stop)\nend\n\nrounded_corner (generic function with 1 method)\n\n\nHere’s an example of such a rounded corner, the dotted lines show the original sharp corner.\n\n@drawsvg begin\n    scale(150, -150)\n\n    p1 = Point(-0.3, -0.6)\n    p2 = Point(0.5, 0.8)\n    p3 = Point(-0.5, 0.3)\n    r = 0.1\n\n    move(p1)\n    rounded_corner(p1, p2, p3, r)\n    line(p3)\n    sethue(\"black\")\n    setopacity(0.5)\n    strokepath()\n\n    setdash(\"dot\")\n\n    move(p1)\n    line(p2)\n    strokepath()\n    move(p2)\n    line(p3)\n    strokepath()\n\n    sethue(\"red\")\n    circle(p1, 0.03, :fill)\n    circle(p2, 0.03, :fill)\n    circle(p3, 0.03, :fill)\n\nend 400 400\n\n\n\n\n\n\n\n\nNow, we can apply different corner radii to the diamonds and turn them into petals.\n\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        rounded_corner(p2, p3, p4, 0.06)\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n        strokepath()\n    end\n\nend 400 400\n\n\n\n\n\n\n\n\nThere are three negative-space circles cut out of the petals. They resemble scatter plot markers and are a nod to the three circle logo of the Julia language.\nWe can first visualize their location by drawing them on top of what we already have.\n\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        rounded_corner(p2, p3, p4, 0.06)\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n        strokepath()\n\n        circle(cs[i], rs[i], :stroke)\n    end\nend 400 400\n\n\n\n\n\n\n\n\nWe can now intersect each petal with its two adjacent circles and draw the corresponding circular arcs. With that, we are done with the shape of the logo.\n\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        c1 = cs[mod1(i + 1, 3)]\n        c2 = cs[mod1(i + 0, 3)]\n\n        n, ip1, ip2 = intersectionlinecircle(p2, p3, c1, rs[mod1(i + 1, 3)])\n        if n != 2\n            error()\n        end\n        n, ip3, ip4 = intersectionlinecircle(p3, p4, c2, rs[mod1(i + 0, 3)])\n        if n != 2\n            error()\n        end\n\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        line(ip2)\n        carc2r(c1, ip2, ip1)\n\n        rounded_corner(p2, p3, p4, 0.06)\n        line(ip4)\n        carc2r(c2, ip4, ip3)\n\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n        strokepath()\n    end\nend 400 400\n\n\n\n\n\n\n\n\nThe coloring actually needed a bit more thought, because in the original this was done in a messy, freehand way with a four-cornered mesh gradient, two corners of which I overlaid to simulate a triangular shape. First I didn’t have an idea how to transform the three Makie colors into a similar gradient programmatically, linear and radial gradients which are inbuilt into SVG do not work.\n\nmakieyellow = colorant\"#e8cb26\"\nmakieblue = colorant\"#3182bb\"\nmakiered = colorant\"#dd3366\"\n\n[makieyellow, makieblue, makiered]\n\n\n\n\n\n\n\n\nThen I realized that there’s a pretty obvious way to compute the mixture of the colors, just use the same math that shaders use to combine vertex colors of triangles in a mesh, which is what Makie itself does. This is called barycentric interpolation.\nThis function computes barycentric weights for three vertices given some point p:\n\nfunction bary_weights(p, v1, v2, v3)\n    den = ((v2[2] - v3[2]) * (v1[1] - v3[1]) + (v3[1] - v2[1]) * (v1[2] - v3[2]))\n    w1 = ((v2[2] - v3[2]) * (p[1] - v3[1]) + (v3[1] - v2[1]) * (p[2] - v3[2])) / den\n    w2 = ((v3[2] - v1[2]) * (p[1] - v3[1]) + (v1[1] - v3[1]) * (p[2] - v3[2])) / den\n    w3 = 1 - w1 - w2\n    (w1, w2, w3)\nend\n\nbary_weights (generic function with 1 method)\n\n\nWe also need some function to mix three rgb colors together, I only found weighted_color_mean in Colors.jl which could only handle two colors, so I wrote some separate function which I don’t remember why it ended up looking this complex.\n\n\nCode\n_tuple(l::Lab) = (l.l, l.a, l.b)\n_tuple(r::RGB) = (r.r, r.g, r.b)\n_tuple(l::LCHuv) = (l.l, l.c, l.h)\n\n# could reduce weighted_color_mean with 1/i\nfunction mix(cfs...)\n    T = typeof(first(first(cfs)))\n    isempty(cfs) && return T(RGBf(1, 1, 1))\n    if any(cf -&gt; cf[2] == 0, cfs)\n        mix(filter(cf -&gt; cf[2] != 0, cfs)...)\n    else\n        if length(cfs) == 1\n            return cfs[1][1]\n        else\n            scaled = map(cfs) do (c, f)\n                f .* _tuple(c)\n            end\n            _sum = foldl((a, b) -&gt; a .+ b, scaled)\n            _sum_scaled = _sum ./ sum(last.(cfs))\n            return T(_sum_scaled...)\n        end\n    end\nend\n\n\nmix (generic function with 1 method)\n\n\nSo with that, we can give it a first try, we determine the bounding box of the outline and compute barycentrically weighted mixtures of the three Makie colors with vertices placed at the petal corners.\nBelow, I just clip that grid to the petal corner triangle so it is easier to see the barycentric mixture.\n\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        push!(cornerpoints, p1)\n    end\n\n    xrange = range(-1, 1, length=10)\n    yrange = range(-1.2, 0.8, length=10)\n\n    pixels = broadcast(xrange, yrange') do i, j\n        p = Point(i, j)\n        f_yellow, f_blue, f_red = clamp.(bary_weights(p, cornerpoints...), 0, 1)\n        mix(((makieyellow), f_yellow), ((makieblue), f_blue), ((makiered), f_red))\n    end\n\n    move(cornerpoints[1])\n    line.(cornerpoints[2:3])\n    closepath()\n    clip()\n\n    @layer begin\n        translate(first(xrange), first(yrange))\n        scale(1 / length(xrange) * (last(xrange) - first(xrange)), 1 / length(yrange) * (last(yrange) - first(yrange)))\n\n        midx = 0.5 * (first(xrange) + last(xrange))\n        midy = 0.5 * (first(yrange) + last(yrange))\n        placeimage(pixels', O, centered=false)\n    end\n\nend 400 400\n\n\n\n\n\n\n\n\nIf you compare that gradient to the original logo:\n\nYou notice that three Makie colors take more space there, each petal is mostly one color but fades into the neighboring petal at the edges.\nI could solve this by exponentiating the barycentric weights. I experimented with different numbers and arrived at 2.1 as a pretty good fit.\n\n\nCode\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        push!(cornerpoints, p1)\n    end\n\n    xrange = range(-1, 1, length=10)\n    yrange = range(-1.2, 0.8, length=10)\n\n    pixels = broadcast(xrange, yrange') do i, j\n        p = Point(i, j)\n        f_yellow, f_blue, f_red = clamp.(bary_weights(p, cornerpoints...), 0, 1) .^ 2.1\n        mix(((makieyellow), f_yellow), ((makieblue), f_blue), ((makiered), f_red))\n    end\n\n    move(cornerpoints[1])\n    line.(cornerpoints[2:3])\n    closepath()\n    clip()\n\n    @layer begin\n        translate(first(xrange), first(yrange))\n        scale(1 / length(xrange) * (last(xrange) - first(xrange)), 1 / length(yrange) * (last(yrange) - first(yrange)))\n\n        midx = 0.5 * (first(xrange) + last(xrange))\n        midy = 0.5 * (first(yrange) + last(yrange))\n        placeimage(pixels', O, centered=false)\n    end\n\nend 400 400\n\n\n\n\n\n\n\n\n\nAnd this is how that triangle looks overlaid on the logo outline:\n\n\nCode\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        c1 = cs[mod1(i + 1, 3)]\n        c2 = cs[mod1(i + 0, 3)]\n\n        n, ip1, ip2 = intersectionlinecircle(p2, p3, c1, rs[mod1(i + 1, 3)])\n        if n != 2\n            error()\n        end\n        n, ip3, ip4 = intersectionlinecircle(p3, p4, c2, rs[mod1(i + 0, 3)])\n        if n != 2\n            error()\n        end\n\n        push!(cornerpoints, p1)\n\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        line(ip2)\n        carc2r(c1, ip2, ip1)\n\n        rounded_corner(p2, p3, p4, 0.06)\n        line(ip4)\n        carc2r(c2, ip4, ip3)\n\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n\n    end\n\n    path = pathtopoly()\n\n    strokepath()\n\n    move(cornerpoints[1])\n    line.(cornerpoints[2:3])\n    closepath()\n    clip()\n\n    xrange = range(extrema(x -&gt; x.x, Iterators.flatten(path))..., length=10)\n    yrange = range(extrema(x -&gt; x.y, Iterators.flatten(path))..., length=10)\n\n    pixels = broadcast(xrange, yrange') do i, j\n        p = Point(i, j)\n        f_yellow, f_blue, f_red = clamp.(bary_weights(p, cornerpoints...), 0, 1) .^ 2.1\n        mix(((makieyellow), f_yellow), ((makieblue), f_blue), ((makiered), f_red))\n    end\n\n    translate(first(xrange), first(yrange))\n    scale(1 / length(xrange) * (last(xrange) - first(xrange)), 1 / length(yrange) * (last(yrange) - first(yrange)))\n\n    midx = 0.5 * (first(xrange) + last(xrange))\n    midy = 0.5 * (first(yrange) + last(yrange))\n    placeimage(pixels', O, centered=false)\n\nend 400 400\n\n\n\n\n\n\n\n\n\nTo arrive at the final result, I simply remove the triangle and switch the logo shape from a stroked outline to a clipping mask for the full gradient mesh. Outside of the triangle negative barycentric weights are simply clipped to zero.\n\n@drawsvg begin\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(150, -150)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        c1 = cs[mod1(i + 1, 3)]\n        c2 = cs[mod1(i + 0, 3)]\n\n        n, ip1, ip2 = intersectionlinecircle(p2, p3, c1, rs[mod1(i + 1, 3)])\n        if n != 2\n            error()\n        end\n        n, ip3, ip4 = intersectionlinecircle(p3, p4, c2, rs[mod1(i + 0, 3)])\n        if n != 2\n            error()\n        end\n\n        push!(cornerpoints, p1)\n\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        line(ip2)\n        carc2r(c1, ip2, ip1)\n\n        rounded_corner(p2, p3, p4, 0.06)\n        line(ip4)\n        carc2r(c2, ip4, ip3)\n\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n\n    end\n\n    path = pathtopoly()\n\n    clip()\n\n    xrange = range(extrema(x -&gt; x.x, Iterators.flatten(path))..., length=10)\n    yrange = range(extrema(x -&gt; x.y, Iterators.flatten(path))..., length=10)\n\n    pixels = broadcast(xrange, yrange') do i, j\n        p = Point(i, j)\n        f_yellow, f_blue, f_red = clamp.(bary_weights(p, cornerpoints...), 0, 1) .^ 2.1\n        mix(((makieyellow), f_yellow), ((makieblue), f_blue), ((makiered), f_red))\n    end\n\n    translate(first(xrange), first(yrange))\n    scale(1 / length(xrange) * (last(xrange) - first(xrange)), 1 / length(yrange) * (last(yrange) - first(yrange)))\n\n    midx = 0.5 * (first(xrange) + last(xrange))\n    midy = 0.5 * (first(yrange) + last(yrange))\n    placeimage(pixels', O, centered=false)\n\nend 400 400\n\n\n\n\n\n\n\n\nAnd that’s it! We can compare once more to the original:\n\nI think that’s a pretty good match, and the size of the new version is just 3KB with a 10x10 pixel gradient.\nFinally, I have to do one animation, just because I can do it now!\n\n\nCode\nfunction frame(scene, framenumber)\n\n    background(\"white\")\n\n    inner_gap = 0.045 / cosd(30)\n\n    scale(250, -250)\n\n    cornerpoints = []\n\n    cs = [\n        Point(0, 0.45),\n        rotatepoint(Point(0, 0.45), 2pi / 3),\n        rotatepoint(Point(0, 0.45), 2 * 2pi / 3),\n    ]\n    rs = [0.15, 0.235, 0.195]\n\n    for i in 1:3\n        p1 = Point(1, 0)\n        p3 = Point(0, 0)\n        p2 = Point(0.5, sqrt(3) / 2)\n        p4 = Point(0.5, -sqrt(3) / 2)\n\n        (p1, p2, p3, p4) = rotatepoint.(Point(inner_gap, 0) .+ (p1, p2, p3, p4), i * 2pi / 3 + 2pi / 12)\n\n        c1 = cs[mod1(i + 1, 3)]\n        c2 = cs[mod1(i + 0, 3)]\n\n        n, ip1, ip2 = intersectionlinecircle(p2, p3, c1, rs[mod1(i + 1, 3)])\n        if n != 2\n            error()\n        end\n        n, ip3, ip4 = intersectionlinecircle(p3, p4, c2, rs[mod1(i + 0, 3)])\n        if n != 2\n            error()\n        end\n\n        push!(cornerpoints, rotatepoint(p1, (framenumber - 1) / 99 * 2pi))\n\n\n        move(p1)\n        rounded_corner(p1, p2, p3, 0.17)\n        line(ip2)\n        carc2r(c1, ip2, ip1)\n\n        rounded_corner(p2, p3, p4, 0.06)\n        line(ip4)\n        carc2r(c2, ip4, ip3)\n\n        rounded_corner(p3, p4, p1, 0.17)\n        closepath()\n\n\n    end\n\n    path = pathtopoly()\n\n    clip()\n\n    xrange = range(extrema(x -&gt; x.x, Iterators.flatten(path))..., length=50)\n    yrange = range(extrema(x -&gt; x.y, Iterators.flatten(path))..., length=50)\n\n    pixels = broadcast(xrange, yrange') do i, j\n        p = Point(i, j)\n        f_yellow, f_blue, f_red = clamp.(bary_weights(p, cornerpoints...), 0, 1) .^ 2.1\n        mix(((makieyellow), f_yellow), ((makieblue), f_blue), ((makiered), f_red))\n    end\n\n    translate(first(xrange), first(yrange))\n    scale(1 / length(xrange) * (last(xrange) - first(xrange)), 1 / length(yrange) * (last(yrange) - first(yrange)))\n\n    midx = 0.5 * (first(xrange) + last(xrange))\n    midy = 0.5 * (first(yrange) + last(yrange))\n    placeimage(pixels', O, centered=false)\n\nend\n\nmovie = Movie(600, 600, \"makielogo\")\n\nmktempdir() do dir\n    animate(movie, [Scene(movie, frame, 0:100)]; tempdirectory = dir)\n    run(`ffmpeg -i $(dir)/%10d.png -y -pix_fmt yuv420p -c:v libx264 -movflags +faststart -filter:v crop='floor(in_w/2)*2:floor(in_h/2)*2' makie.mp4`)\nend"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Recreating the Makie logo with Luxor.jl\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nMay 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRAW photo library automation with Julia\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting data from Harry Potter with GPT-3\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nOct 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPkg.jl and Julia Environments for Beginners\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nAug 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nComposing macros inside-out with Julia\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nDec 28, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing international football results with Julia\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nJun 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nJulia macros for beginners\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nJun 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nReading data from the web with CSV.jl, DataFrames.jl and Chain.jl\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nMay 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nTuples and Vectors, Allocations and Performance for Beginners\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nOct 31, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nJulia Helps To Bridge The Gap Between User and Creator\n\n\n\n\n\n\njulia\n\n\n\n\n\n\n\n\n\nOct 23, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "For my work, I mostly use the Julia programming language and occasionally write about aspects I find interesting here.\nI’m a main contributor to the Makie plotting ecosystem for which I wrote the layouting system. I also maintain a couple of Julia packages such as the data wrangling macro tool Chain.jl, the tweening library Animations.jl and the regex helper ReadableRegex.jl."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "",
    "text": "DataFrameMacros.jl is a Julia package that makes it easier to manipulate DataFrames, by rewriting code into source-function-sink expressions that conform to DataFrames.jl’s more verbose mini-language. In version v0.2 (and v0.2.1) I have added a couple new features that are powerful, but not immediately obvious. This post takes a closer look at the new functionality.\nThe new features are multi-column specifiers, shortcut strings for renaming and subset transformations."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#multi-column-specifiers",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#multi-column-specifiers",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Multi-column specifiers",
    "text": "Multi-column specifiers\nSo far, DataFrameMacros.jl only supported statements with single-column specifiers. For example, @select(df, :x + 1) or @combine(df, $column_variable * $2). The expressions :x, $column_variable and $2 all refer to one column each. The underlying source-function-sink expression that DataFrameMacros.jl created was therefore always of the form source =&gt; function =&gt; sink. For many tasks this is perfectly sufficient, but other times one wants to execute the same function over a set of similar or related columns.\nDataFrames.jl has a neat way to run the same function on a set of columns. This is done by using the .=&gt; operator, to broadcast over a set or sets of columns and create an array of source =&gt; function =&gt; sink expressions. For example, you could compute the sum for each column in a DataFrame with transform(df, names(df, All()) .=&gt; sum), or in the recent v1.3 release even with transform(df, All() .=&gt; sum).\nNow, the trick that DataFrameMacros.jl v0.2.1 uses is to change the underlying representation from source =&gt; function =&gt; sink to source(s) .=&gt; function(s) .=&gt; sink(s). This doesn’t break the existing functionality, because scalars in Julia broadcast just fine, so it’s no problem to say something like combine(df, :x .=&gt; sum .=&gt; \"y\") - even though broadcasting doesn’t add anything if only scalars participate.\nWhere it gets interesting is when collections of columns are used. With the change to source(s) .=&gt; function(s) .=&gt; sink(s) you are now free to use column expressions that refer to multiple columns. The only restriction is that the shapes of source(s), function(s) and sink(s) have to be compatible for broadcasting.\nThere are multiple ways in which you can reference multiple columns at once, and they are closely related to what x can be in the function names(df, x). For example, All(), Between(x, y) and Not(args...) are now recognized directly as multi-column specifiers by DataFrameMacros, without having to mark them with the usual $ sign. Then you can use any Type T marked by $, which selects all columns whose elements are subtypes of T, for example $Real or $String. You can use a regex that selects all columns with matching names, for example $(r\"a\") for any column with the letter a. Of course it’s also possible to just pass an array of column names, for example $[\"a\", \"b\"].\nHere are a few practical examples:\n\nusing DataFrameMacros\nusing DataFrames\n\ndf = DataFrame(\n    name = [\"alice\", \"bob\", \"charlie\"],\n    age = [20, 31, 42],\n    country = [\"andorra\", \"brazil\", \"croatia\"],\n    salary = [9999, 6666, 3333],\n)\n\n\n3 rows × 4 columns\n\n\n\n\nname\nage\ncountry\nsalary\n\n\n\nString\nInt64\nString\nInt64\n\n\n\n\n1\nalice\n20\nandorra\n9999\n\n\n2\nbob\n31\nbrazil\n6666\n\n\n3\ncharlie\n42\ncroatia\n3333\n\n\n\n\n\n\n\nWe can transform both String columns at once and both Int columns at once, by using the Type multi-column specifier.\n\n@select df begin\n    uppercasefirst($String)\n    Float64($Int)\nend\n\n\n3 rows × 4 columns\n\n\n\n\nname_uppercasefirst\ncountry_uppercasefirst\nage_Float64\nsalary_Float64\n\n\n\nString\nString\nFloat64\nFloat64\n\n\n\n\n1\nAlice\nAndorra\n20.0\n9999.0\n\n\n2\nBob\nBrazil\n31.0\n6666.0\n\n\n3\nCharlie\nCroatia\n42.0\n3333.0\n\n\n\n\n\n\n\nWe can try out the All() specifier by reversing the element order of each column. We need the @c flag so reverse acts on each column vector and not each column element. This works the same way with the Between and Not selectors.\n\n@select df @c reverse(All())\n\n\n3 rows × 4 columns\n\n\n\n\nname_reverse\nage_reverse\ncountry_reverse\nsalary_reverse\n\n\n\nString\nInt64\nString\nInt64\n\n\n\n\n1\ncharlie\n42\ncroatia\n3333\n\n\n2\nbob\n31\nbrazil\n6666\n\n\n3\nalice\n20\nandorra\n9999\n\n\n\n\n\n\n\nWe can combine multi-column specifiers with single-column specifiers, they can always broadcast together because scalars work together with any shape. For example, let’s say we have a column with tax rates and four columns with quarterly gains and we want to compute the quarterly taxes.\n\ndf = DataFrame(\n    year = [2019, 2020, 2021],\n    tax_rate = [0.19, 0.20, 0.21],\n    income_q1 = [2000, 3000, 4000],\n    income_q2 = [2100, 3100, 4100],\n    income_q3 = [2200, 3200, 4200],\n    income_q4 = [2300, 3300, 4300],\n)\n\n\n3 rows × 6 columns\n\n\n\n\nyear\ntax_rate\nincome_q1\nincome_q2\nincome_q3\nincome_q4\n\n\n\nInt64\nFloat64\nInt64\nInt64\nInt64\nInt64\n\n\n\n\n1\n2019\n0.19\n2000\n2100\n2200\n2300\n\n\n2\n2020\n0.2\n3000\n3100\n3200\n3300\n\n\n3\n2021\n0.21\n4000\n4100\n4200\n4300\n\n\n\n\n\n\n\nThen we can simply multiply the tax rate with the four income columns at once, which we select with the Between selector.\n\n@select(df, :tax_rate * Between(3, 6))\n\n\n3 rows × 4 columns\n\n\n\n\ntax_rate_income_q1_*\ntax_rate_income_q2_*\ntax_rate_income_q3_*\ntax_rate_income_q4_*\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n399.0\n418.0\n437.0\n\n\n2\n600.0\n620.0\n640.0\n660.0\n\n\n3\n840.0\n861.0\n882.0\n903.0\n\n\n\n\n\n\n\nAnother option to select the columns would be to use a regex. We have to mark it with $ so that DataFrameMacros knows to treat it as a column specifier.\n\n@select(df, :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columns\n\n\n\n\ntax_rate_income_q1_*\ntax_rate_income_q2_*\ntax_rate_income_q3_*\ntax_rate_income_q4_*\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n399.0\n418.0\n437.0\n\n\n2\n600.0\n620.0\n640.0\n660.0\n\n\n3\n840.0\n861.0\n882.0\n903.0\n\n\n\n\n\n\n\nNow one issue is that the resulting column names are very ugly. We could specify the new names directly as a vector. Remember that the expression is source(s) .=&gt; function(s) .=&gt; sink(s) so we can also broadcast a vector of sinks. The string \"taxes_q1\" will be the sink associated with the first element from the regex selector, and so on.\n\n@select(df,\n    [\"taxes_q1\", \"taxes_q2\", \"taxes_q3\", \"taxes_q4\"] = :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columns\n\n\n\n\ntaxes_q1\ntaxes_q2\ntaxes_q3\ntaxes_q4\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n399.0\n418.0\n437.0\n\n\n2\n600.0\n620.0\n640.0\n660.0\n\n\n3\n840.0\n861.0\n882.0\n903.0\n\n\n\n\n\n\n\nBut writing out strings like that is error prone, especially if the order of columns can change. So it would be better to transform the original column names. DataFrames allows to use anonymous functions for this, the input for the function is a vector with all column names used in the expression. We can split off the \"q1\" part from the second column in each expression (the income column) and prefix with \"taxes_\":\n\n@select(df, (names -&gt; \"taxes_\" * split(names[2], \"_\")[2]) = :tax_rate * $(r\"income\"))\n\n\n3 rows × 4 columns\n\n\n\n\ntaxes_q1\ntaxes_q2\ntaxes_q3\ntaxes_q4\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n399.0\n418.0\n437.0\n\n\n2\n600.0\n620.0\n640.0\n660.0\n\n\n3\n840.0\n861.0\n882.0\n903.0\n\n\n\n\n\n\n\n\nBroadcasting with more than one dimension\nYou are not technically limited to broadcasting one vector of columns with scalar columns, you can even evaluate two- or higher-dimensional grids of column combinations if you like. For example, if you had two different tax rates and three income categories, you could compute all six tax columns with one expression. Here we extract the income columns first so we can make them into a row-vector with permutedims, which will form a 2D grid when broadcasted together with the column vector with the two tax columns.\n\ndf = DataFrame(\n    year = [2019, 2020, 2021],\n    tax_a = [0.19, 0.20, 0.21],\n    tax_b = [0.22, 0.23, 0.24],\n    income_a = [2000, 3000, 4000],\n    income_b = [2100, 3100, 4100],\n    income_c = [2200, 3200, 4200],\n)\n\nincome_cols = permutedims(names(df, r\"income\"))\n\n@select(df, $(r\"tax\") * $income_cols)\n\n\n3 rows × 6 columns (omitted printing of 1 columns)\n\n\n\n\ntax_a_income_a_*\ntax_b_income_a_*\ntax_a_income_b_*\ntax_b_income_b_*\ntax_a_income_c_*\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n440.0\n399.0\n462.0\n418.0\n\n\n2\n600.0\n690.0\n620.0\n713.0\n640.0\n\n\n3\n840.0\n960.0\n861.0\n984.0\n882.0\n\n\n\n\n\n\n\nThe column names are again not ideal, which brings us to another new feature."
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#shortcut-strings-for-renaming",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#shortcut-strings-for-renaming",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Shortcut strings for renaming",
    "text": "Shortcut strings for renaming\nOften, we want to give new columns names that are just simple combinations of column names used to compute them. In the last example, a better name than tax_a_income_a_* could be tax_a_on_income_b.\nIf DataFrameMacros encounters a string literal as the sink which contains \"{}\", \"{1}\" or \"{2}\" and up, it translates this into a renaming function that pastes the input column names at the respective locations. Here’s the last example again with such a shortcut string:\n\n@select(df, \"{1}_on_{2}\" = $(r\"tax\") * $income_cols)\n\n\n3 rows × 6 columns (omitted printing of 1 columns)\n\n\n\n\ntax_a_on_income_a\ntax_b_on_income_a\ntax_a_on_income_b\ntax_b_on_income_b\ntax_a_on_income_c\n\n\n\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n380.0\n440.0\n399.0\n462.0\n418.0\n\n\n2\n600.0\n690.0\n620.0\n713.0\n640.0\n\n\n3\n840.0\n960.0\n861.0\n984.0\n882.0"
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#subset-transformations",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#subset-transformations",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Subset transformations",
    "text": "Subset transformations\nThe third new feature goes hand in hand with a new addition in DataFrames v1.3. Now you can call transform! or select! on the view returned by subset(df, some_subset_expression, view = true), and this will mutate the underlying DataFrame only in the selected rows. If new columns are added, all rows outside the subset are filled with missing values.\nIn base DataFrames, you need to first create a subset view, then mutate it, then continue on with the original DataFrame. Here’s the DataFrame we start with\n\ndf = DataFrame(x = 1:4, y = 5:8)\n\n\n4 rows × 2 columns\n\n\n\n\nx\ny\n\n\n\nInt64\nInt64\n\n\n\n\n1\n1\n5\n\n\n2\n2\n6\n\n\n3\n3\n7\n\n\n4\n4\n8\n\n\n\n\n\n\n\nNow we subset some rows and increment the y values by 10 there. We also create new z values:\n\nsubset_view = subset(df, :x =&gt; ByRow(&gt;=(3)), view = true)\ntransform!(\n    subset_view,\n    :y =&gt; ByRow(x -&gt; x + 10) =&gt; :y,\n    :x =&gt; (x -&gt; x * 3) =&gt; :z\n)\ndf\n\n\n4 rows × 3 columns\n\n\n\n\nx\ny\nz\n\n\n\nInt64\nInt64\nInt64?\n\n\n\n\n1\n1\n5\nmissing\n\n\n2\n2\n6\nmissing\n\n\n3\n3\n17\n9\n\n\n4\n4\n18\n12\n\n\n\n\n\n\n\nIn DataFrameMacros v0.2, you can now use a more convenient syntax that plays well with Chain.jl or other piping mechanisms, where you only want to use functions that return the DataFrame you work with, not a subset view. You can simply pass a @subset expression to @transform! or @select! after the DataFrame argument. This @subset expression doesn’t take its own DataFrame argument as usual, that’s implied to be the DataFrame that is being transformed. The returned object after mutating the selected rows is the original DataFrame. You can see how much more concise the same operation becomes:\n\ndf = DataFrame(x = 1:4, y = 5:8)\n@transform!(df, @subset(:x &gt;= 3), :y = :y + 10, :z = 3 * :x)\n\n\n4 rows × 3 columns\n\n\n\n\nx\ny\nz\n\n\n\nInt64\nInt64\nInt64?\n\n\n\n\n1\n1\n5\nmissing\n\n\n2\n2\n6\nmissing\n\n\n3\n3\n17\n9\n\n\n4\n4\n18\n12"
  },
  {
    "objectID": "pages/2021-12-28-new-features-dataframemacros/index.html#summary",
    "href": "pages/2021-12-28-new-features-dataframemacros/index.html#summary",
    "title": "Multi-columns, shortcut strings and subset transformations in DataFrameMacros.jl v0.2",
    "section": "Summary",
    "text": "Summary\nThat concludes the overview of the three new features, multi-column specifiers, shortcut strings for renaming and subset transformations. Especially multi-column specifiers with their implicit broadcasting might need a moment to wrap your head around, but I think you’ll find them very convenient. I hope you enjoy using the new release!"
  },
  {
    "objectID": "pages/2022-08-09-composing-macros/index.html",
    "href": "pages/2022-08-09-composing-macros/index.html",
    "title": "Composing macros inside-out with Julia",
    "section": "",
    "text": "Macros vs. functions\nMacros in Julia, denoted by the @ prefix, are used to transform code before it is executed. They are often used to reduce boilerplate or implement domain specific languages (DSLs).\nIn a way, they are just normal functions which take in an abstract syntax tree or AST and return a different one, and their execution happens before that of all the normal code.\nWhile functions run inside-out, macros run outside-in. When you execute outer(inner(x)) then the inner function runs first, and outer takes in what inner outputs. But if you execute @outer(@inner(x)), then @outer runs first, only after which any remaining macros inside the AST it outputs are run. In this example could still be @inner depending on what @outer outputs, but it doesn’t have to be. For example, there could be a @remove_macros macro, which just deletes any macro calls inside its body.\n\n\nMacros don’t compose\nOne problematic consequence of this is that macros do not really compose. For example, let’s say you have two macros that operate on function definitions and add some useful things to them.\nLet’s make one which wraps the body of a function in a timing operation. Note that I do this with an inner function as a quick-and-dirty way, because otherwise I have to deal with possibly multiple return statements from the function body.\n\nmacro functime(expr)\n    expr.head == :function || error(\"Not a function expression.\")\n    funcname = expr.args[1].args[1]\n    :(\n        function $(esc(funcname))(args...; kwargs...)\n            f = $expr\n            println(\"Started execution at $(time())\")\n            result = f(args...; kwargs...)\n            println(\"Stopped execution at $(time())\")\n            return result\n        end\n    )\nend\n\n@functime function func()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc()\n\nStarted execution at 1.714752755314152e9\nStopped execution at 1.714752755823732e9\n\n\n\"result\"\n\n\nAnd here’s one that just logs that the function is being run:\n\nmacro funclog(expr)\n    expr.head == :function || error(\"Not a function expression.\")\n    funcname = expr.args[1].args[1]\n    :(\n        function $(esc(funcname))(args...; kwargs...)\n            f = $expr\n            @info(\"Running function.\")\n            result = f(args...; kwargs...)\n            return result\n        end\n    )\nend\n\n@funclog function func2()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc2()\n\n[ Info: Running function.\n\n\n\"result\"\n\n\nBut you cannot use both macros at once on a single function definition, because each macro expects an expression in form of a function definition as its argument. And putting a different macro inside means that the expression is of type :macrocall and not type :function, which our macros don’t know how to deal with.\nSo this doesn’t work:\n@functime @funclog function func3()\n    sleep(0.5)\n    return \"result\"\nend\nOf course we can use higher-order functions for what I’m showing here, but that’s not the point of the exercise, it’s to try and see if we can use macros in a layered / composed way.\n\n\nThe inside-out macro\nWhat I wanted to try here was to make the macros run from inside-out, like functions. For this, I made another small meta-macro which calls macroexpand from the inside out if it encounters multiple macros (with recursive = false because we want to keep any macros inside the main body intact throughout the transformations like usual). That means @insideout @macro1 @macro2 expr first expands @macro2 expr and then @macro1 output_expr.\n\nmacro insideout(exp)\n    function apply_macro(exp::Expr)\n        if exp isa Expr && exp.head == :macrocall\n            exp.args[3] = apply_macro(exp.args[3])\n            return macroexpand(@__MODULE__, exp, recursive = false)\n        else\n            return exp\n        end\n    end\n    \n    apply_macro(exp)\nend\n\n@insideout (macro with 1 method)\n\n\nThis means one can now compose macros:\n\n@insideout @functime @funclog function func3()\n    sleep(0.5)\n    return \"result\"\nend\n\nfunc3()\n\nStarted execution at 1.714752757224469e9\n[ Info: Running function.\nStopped execution at 1.714752757726876e9\n\n\n\"result\"\n\n\nThese examples are contrived but I wonder if someone can come up with a more interesting use-case for the technique.\nAt least it’s fun trying @insideout with some of the usual macros to modify what happens in an interesting way:\nFor example, using @show on @show:\n\n@show @show 1 + 2\n\n1 + 2 = 3\n#= /Users/krumbiegel/dev/jkrumbiegel.github.io/pages/2022-08-09-composing-macros/index.qmd:130 =# @show(1 + 2) = 3\n\n\n3\n\n\nvs. with the inside-out mode, which turns @show into some weird kind of macroexpand-and-run:\n\n@insideout @show @show 1 + 2\n\n1 + 2 = 3\nbegin\n    Base.println(\"1 + 2 = \", Base.repr(begin\n                #= show.jl:1181 =#\n                local var\"#565#value\" = 1 + 2\n            end))\n    var\"#565#value\"\nend = 3\n\n\n3"
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html",
    "title": "RAW photo library automation with Julia",
    "section": "",
    "text": "In this post I describe how I use Julia to automatically synchronize my Capture One raw photo catalog to my iCloud via Apple Photos, so that I can view and share the jpegs from my iPhone at any time with the same interface as my iPhone photos. The official AppleScript interfaces are not powerful enough to do what I need. My solution is accessing the SQLite databases of Capture One and Apple Photos directly and doing some simple data wrangling which Julia is perfectly suited for."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#summary",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#summary",
    "title": "RAW photo library automation with Julia",
    "section": "",
    "text": "In this post I describe how I use Julia to automatically synchronize my Capture One raw photo catalog to my iCloud via Apple Photos, so that I can view and share the jpegs from my iPhone at any time with the same interface as my iPhone photos. The official AppleScript interfaces are not powerful enough to do what I need. My solution is accessing the SQLite databases of Capture One and Apple Photos directly and doing some simple data wrangling which Julia is perfectly suited for."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-problem",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-problem",
    "title": "RAW photo library automation with Julia",
    "section": "The problem",
    "text": "The problem\nI take a lot of RAW photos with my mirrorless camera whenever there’s any sort of event in my life, for all other situations I usually use my iPhone. For a while I’ve been annoyed that I can’t view and share my high-quality photos as easily as the ones from the phone, because they have to roundtrip through my editing software Capture One first before I export them as jpegs. There is software to host your own photo library somewhere, but that’s too much organizational overhead for me.\nIdeally, I wanted to just have the mirrorless photos appear side-by-side with my iPhone photos in my iPhone’s camera roll. I do have enough space in my iCloud plan to host all the exported jpegs, but I did not want to have them all in a huge pile and I did not want to upload them all manually either. For many years, I have sorted all RAW photos in Capture One and on my hard drive into folders because I wanted this structure to persist across editing software changes (I’ve switched from Lightroom to Capture One before and might switch again at some point). The structure is simple, photos are grouped into folders like 2023/2023-02-03-2023-02-05 Weekend in the mountains. All I wanted was automation with these characteristics:\n\nThere’s no configuration, I only have to run a script or press a button somewhere and all RAW photos not yet in my iCloud collection are exported and uploaded.\nAs Apple Photos doesn’t have physical folders, my folder structure should be mirrored by albums.\nAlready uploaded photos are detected and only exported again if they have been edited again since."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-non-solution-applescript",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-non-solution-applescript",
    "title": "RAW photo library automation with Julia",
    "section": "The non-solution: AppleScript",
    "text": "The non-solution: AppleScript\nBoth Capture One and Apple Photos have AppleScript interfaces for automation. So I spent quite a lot of time trying to get things to work this way, however, I was ultimately not successful or happy with my solutions for these reasons:\n\nAppleScript is weird: I encountered a lot of friction with the unusual syntax and object model. The objects you get back from applications do not behave like those in other object-oriented languages I know. They’re usually lazy queries and a bit hard to predict when storing them over the lifetime of a program. Also, a lot of basic things are more difficult in AppleScript than in Julia, for example mapping over lists or dictionaries. Because I found AppleScript so unwieldy, I actually made two attempts to supplant it with Julia libraries, one for accessing AppleScript via the Objective C Scripting Bridge, and one other, sending apple events directly. Both were doomed to fail due to weirdnesses in implementation that only became visible hours into each project. (JavaScript for automation or JXA is a bit better in terms of programming primitives, but some commands I needed could not be run at all through this interface).\nAppleScript is slow: My Capture One library has about 45,000 images, and I have about 30,000 other images in ApplePhotos. Looping over all of those with AppleScript easily accumulates minutes or even hours of run time just for the bookkeeping.\nMissing things in AppleScript APIs: I need to know when a Capture One image was most recently edited so that I know whether I have to update that image in Apple Photos. But Capture One’s AppleScript interface doesn’t expose editing time. It does expose a lot of useless other tags, I have no idea how such a basic thing slipped past them, or why they decided it was not useful enough to include. It’s the same on the Apple Photos side. I need to know when an image was added to the library, so I can compare that to the edit time on the Capture One side. Again, this information is not exposed via AppleScript. Overwriting all existing photos each time is completely infeasible, that would waste hours or days of rendering time."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-solution-direct-database-access",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#the-solution-direct-database-access",
    "title": "RAW photo library automation with Julia",
    "section": "The solution: Direct database access",
    "text": "The solution: Direct database access\nI had given up hope multiple times to ever solve this issue, only to return again, try, and fail. My photos seemed doomed to reside on my NAS at home where nobody can ever see them (my upload speed is way too slow to serve anything from there). In a moment of frustration I thought “why can’t I just access my freaking photo database like the database that it is”, which was followed by “wait a minute, it probably really is just a database”. After two seconds of googling, I discovered that both Apple Photos and Capture One (and Lightroom, for my older photos) use SQLite databases, just slightly hidden in their own files. This sparked hope that these databases would hold the timestamp information I needed. Naturally, I started a Julia project to find out.\nIn a new environment, I installed SQLite and DataFrames. The Capture One SQLite file is Capture One Catalog.cocatalog/Capture One Catalog.cocatalogdb and that of Apple Photos is Fotos-Mediathek.photoslibrary/database/Photos.sqlite. Before doing any operations, I copied both those files to a mktempdir(), just to be sure I don’t accidentally destroy years of editing work. I then defined\ndfexec(db, sql) = DataFrame(DBInterface.execute(db, sql))\nwhere db should be the output of SQLite.DB(path_to_sqlite_copy). This way I get a DataFrame out from my queries, which I’m more familiar with.\nAfter these first steps, most of the time went into finding out where and how the data I needed was stored. Here’s an example of what the SQL command PRAGMA table_list returns for Capture One:\n22×6 DataFrame\n Row │ schema  name                          type    ncol   wr     strict \n     │ String  String                        String  Int64  Int64  Int64  \n─────┼────────────────────────────────────────────────────────────────────\n   1 │ main    sqlite_stat1                  table       3      0       0\n   2 │ main    ZCOLLECTION                   table      46      0       0\n   3 │ main    ZIMAGEINCOLLECTION            table       4      0       0\n   4 │ main    ZDOCUMENTSETTING              table       4      0       0\n   5 │ main    ZVARIANTLAYER                 table     139      0       0\n   6 │ main    ZSIDECAR                      table       6      0       0\n   7 │ main    ZSELECTEDVARIANTS             table       4      0       0\n   8 │ main    ZPROCESSHISTORY               table       5      0       0\n   9 │ main    ZVARIANTMETADATA              table      41      0       0\n  10 │ main    ZDOCUMENTCONTENT              table      15      0       0\n  11 │ main    ZVERSIONINFO                  table       7      0       0\n  12 │ main    ZENTITIES                     table       2      0       0\n  13 │ main    ZCAPTUREPILOT                 table      17      0       0\n  14 │ main    ZVARIANTINCOLLECTION          table       4      0       0\n  15 │ main    ZENABLEDOUTPUTRECIPE          table       4      0       0\n  16 │ main    ZVARIANT                      table      20      0       0\n  17 │ main    ZKEYWORD                      table       8      0       0\n  18 │ main    ZIMAGEINCOLLECTIONPROPERTIES  table       6      0       0\n  19 │ main    sqlite_schema                 table       5      0       0\n  20 │ main    ZIMAGE                        table      56      0       0\n  21 │ main    ZPATHLOCATION                 table       8      0       0\n  22 │ temp    sqlite_temp_schema            table       5      0       0\nI had a look through most of these and pieced together the data structures I needed. As it turns out, Capture One discriminates between “images” and “variants”. Variants are the descriptions of edits that have been done with a given source image. Every image has at least one variant but can have more. It turned out that almost none of my photos have more than the primary variant, so I decided only to export that one, because a process including secondary variants would have become more complicated for little gain. That’s why I only needed the table ZIMAGEINCOLLECTION to find the collections that the primary variants were in, and not ZVARIANTINCOLLECTION which stores that info for the additional variants.\nThe data I needed had to be pieced together from multiple tables. For example, to get the collections with their source paths on disk:\nSELECT\n    ZCOLLECTION.Z_PK as id_coll,\n    ZCOLLECTION.ZNAME as cname,\n    ZENTITIES.ZNAME as ctype,\n    ZMACROOT as cvolume,\n    ZRELATIVEPATH as cpath\nFROM ZCOLLECTION\nLEFT JOIN ZENTITIES ON\n    ZCOLLECTION.Z_ENT = ZENTITIES.Z_ENT\nLEFT JOIN ZPATHLOCATION ON\n    ZCOLLECTION.ZFOLDERLOCATION = ZPATHLOCATION.Z_PK\nTo get the variants with correct zero-based variant index:\nSELECT\n    Z_PK as id_var,\n    ZLASTMETADATAMODIFICATIONDATE as t_modified,\n    ZIMAGE as id_img,\n    ZINDEX &gt;&gt; 7 as var_index -- bit shifting needed for unknown reasons\nFROM ZVARIANT\nTo get raw image information:\nSELECT\n    Z_PK as id_img,\n    ZDISPLAYNAME as imgname,\n    ZIMAGELOCATION as id_imglocation,\n    ZIMAGEFILENAME as filename\nFROM ZIMAGE\nTimestamps had to be converted from floats via Dates.unix2datetime. I identified all the collections with my year-name pattern by filtering for endswith(:cpath, r\"\\d{4}[^/]+\").\nThe data coming out of this process looks a bit like the following:\n23×9 DataFrame\n Row │ id_coll  id_img  id_var  t_modified               var_index  filename      album                  folder     jpgname      \n     │ Int64    Int64   Int64   DateTime?                Int64      String        String                 SubStrin…  String       \n─────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n   1 │     674   56442   56465  2020-03-04T18:52:55.723          0  DSC08284.ARW  2020-03-04 Some Event  2020       DSC08284.jpg\n   2 │     674   56443   56466  2020-03-04T18:52:57.075          0  DSC08285.ARW  2020-03-04 Some Event  2020       DSC08285.jpg\n   3 │     674   56444   56467  2020-03-04T18:52:58.381          0  DSC08286.ARW  2020-03-04 Some Event  2020       DSC08286.jpg\n   4 │     674   56445   56468  2020-03-04T18:52:59.684          0  DSC08287.ARW  2020-03-04 Some Event  2020       DSC08287.jpg\n   5 │     674   56446   56469  2020-03-04T18:53:00.997          0  DSC08288.ARW  2020-03-04 Some Event  2020       DSC08288.jpg\n   6 │     674   56447   56470  2020-03-04T18:53:02.296          0  DSC08289.ARW  2020-03-04 Some Event  2020       DSC08289.jpg\n   7 │     674   56448   56471  2020-03-04T18:53:03.637          0  DSC08290.ARW  2020-03-04 Some Event  2020       DSC08290.jpg\nOn the Apple Photos side I used this statement:\nSELECT\n    alb.Z_PK as id_album,\n    alb.ZPARENTFOLDER as parentfolder_id,\n    parentalb.ZTITLE as folder,\n    alb.ZTITLE as album,\n    alb.ZTRASHEDSTATE as album_deleted,\n    pk.Z_NAME as albumkind,\n    Z_3ASSETS as id_asset,\n    assattr.ZORIGINALFILENAME as jpgname,\n    ZASSET.ZADDEDDATE as t_added,\n    ZASSET.ZDATECREATED as t_created\nFROM ZGENERICALBUM as alb\nLEFT JOIN Z_PRIMARYKEY as pk ON\n    alb.Z_ENT = pk.Z_ENT\nINNER JOIN Z_27ASSETS ON    -- Z_XXASSETS, where XX is the id of the Album entity\n    id_album == Z_27ALBUMS\nLEFT JOIN ZASSET ON\n    id_asset == ZASSET.Z_PK\nLEFT JOIN ZADDITIONALASSETATTRIBUTES as assattr ON\n    id_asset == assattr.ZASSET\nLEFT JOIN ZGENERICALBUM as parentalb ON\n    alb.ZPARENTFOLDER == parentalb.Z_PK\nWHERE (album IS NOT NULL OR id_album == 1) AND album_deleted == 0\nThis is kind of specific to my own machine, the Z_27ALBUMS table for example can be called something else depending on the id of the Album entity in the entities table. In this case, the time stamps needed to be transformed using DateTime(2001, 1, 1) + Second(round(Int, :t_added)) as I found out after a bit of googling.\nI wrote some data wrangling logic to extract three fields for each photo in both dataframes, :folder, :album, :jpgname. I could not use the photo timestamp as a unique ID to match photos because it has only a resolution of seconds, so there are many photos from bursts sharing the same timestamp. I relied on the folder structure plus original filename for matching, as I always just keep filenames when exporting, so DSC1234.ARW becomes DSC1234.jpg which can be read out on the Apple Photos side as ZORIGINALFILENAME.\nNow that I had these two dataframes, my queries became simple join statements. To find all photos that are already exported to Apple Photos:\nin_photos = innerjoin(dfco, dfphotos, on = [:folder, :album, :jpgname])\nTo find all photos in this dataframe that have since been edited in Capture One and should be updated:\nusing DataFrameMacros\n@subset in_photos (:t_modified &gt; :t_added) === true # === because of missings\nTo find all photos that are not yet in Apple Photos:\nnot_in_photos = antijoin(dfco, dfphotos, on = [:folder, :album, :jpgname])\nThis was the core of the solution of my problem. It was beautiful to be able to write simple DataFrames queries against the data, while having to reimplement something like antijoin in AppleScript would have been quite horrible I’m sure. Having the Julia REPL for interactively exploring the data that I don’t yet understand is much nicer than doing the same in AppleScript, which doesn’t even have obvious inbuilt print logging…\nThe last part of the post spells out a bit more how I could actually get the photos exported from Capture One and imported into Apple Photos after they had been identified. Here I did use some AppleScript after all."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#exporting-and-importing-applescript-is-back",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#exporting-and-importing-applescript-is-back",
    "title": "RAW photo library automation with Julia",
    "section": "Exporting and importing: AppleScript is back",
    "text": "Exporting and importing: AppleScript is back\nFor making Capture One and Apple Photos do anything, you sadly can’t avoid AppleScript. But I wanted to spend as little time as possible there, so I decided to stay in Julia and only execute snippets of AppleScript via the osascript executable. This is thankfully pretty easy with Julia’s Cmds.\nIn principle the logic is simple, choose a batch of photos from the dataframe of unexported photos, tell Capture One to export them somewhere, and tell Apple Photos to import them into the correct album.\nThere’s some more complication to this (of course there is, there always is). The first one is that I always want to use temporary folders so that my workflows don’t depend on the directory structure I had at the time of writing them. But Capture One doesn’t allow you to just process to some folder, you can only process recipes. So I set the path on a specific recipe I only use for this purpose, each time I process a new batch.\nThis looks something like:\nmktempdir() do dir\n    scr = \"\"\"\n    tell application \"Capture One 23\"\n        set d to current document\n        set r to recipe \"icloud jpg export\" of d\n        set root folder location of r to \"$dir\"\n        set v to {$variantstring}\n        process v recipe \"icloud jpg export\"\n        return\n    end tell\n    \"\"\"\n    @info \"Waiting for processing...\"\n    run(`osascript -e $scr`)\n\n    # other logic before cleaning up\nend\nThe variable variantstring is a pre-made string of AppleScript expressions that accesses the correct variants in Capture One. In this snippet sdf is the sub-dataframe containing the rows I want to export in a batch.\nvariantstring = join([\"(variant id \\\"$i\\\" of collection id \\\"$coll\\\" of d)\" for (i, coll) in zip(sdf.id_var, sdf.id_coll)], \", \")"
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#getting-capture-one-to-call-back",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#getting-capture-one-to-call-back",
    "title": "RAW photo library automation with Julia",
    "section": "Getting Capture One to call back",
    "text": "Getting Capture One to call back\nOk, so now I could process images to a temporary folder. The next complication was that osascript returns before the exported images are ready. There’s no simple “callback” from Capture One that tells me when I can start importing to Apple Photos. There’s only a batch done script property I can set via AppleScript, where Capture One will call that script when it has finished a batch. This is in principle prone to errors, were I to interact with Capture One at the same time my script runs, but I don’t have to make things more complicated than they need to be and just refrain from doing that.\nMy little workaround to make the osascript more callback-y was:\n\nCreate a temporary AppleScript file.\nThis file contains logic to write a new random UUID to another empty file next to it.\nSet this script file as Capture One’s batch done script.\nStart Capture One’s processing.\nStart watching the empty file with Julia’s FileWatching.\nOnce Capture One is done, and the file is being written to, FileWatching.watch_file returns.\nRead the sentinel file, check that the UUID matches the generated one, otherwise some mixup may have happened an error is thrown.\nFinally set Capture One’s batch done script to an empty string to disable the functionality.\n\nThis actually worked pretty well and made the whole process much more pleasant. I had tried out watching the folder for the known number of exported files, but this was problematic if the Capture One processing failed half-way for some reason. Then the required number would never be reached without me knowing why (AppleScript doesn’t return processing errors). But if the batch done script fires and the number of images is not right, I know something is incorrect (usually something with a raw file being unavailable temporarily due to network issues)."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#final-hickups-importing-into-apple-photos",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#final-hickups-importing-into-apple-photos",
    "title": "RAW photo library automation with Julia",
    "section": "Final hickups: Importing into Apple Photos",
    "text": "Final hickups: Importing into Apple Photos\nOnce a batch of photos is done, I use this code to import them into Apple Photos:\nfilesstring = join([\"(POSIX file \\\"$f\\\")\" for f in filepaths], \", \")\n\nscr2 = \"\"\"\nwith timeout of 86400 seconds\n    tell application \"Photos\"\n\n        if not (exists folder \"$folder\" of folder \"Kamera\")\n            make new folder named \"$folder\" at folder \"Kamera\"\n        end if\n\n        set fol to folder \"$folder\" of folder \"Kamera\"\n\n        if not (exists album \"$album\" of fol)\n            make new album named \"$album\" at fol\n        end\n\n        set alb to album \"$album\" of fol\n\n        set imagefiles to {$filesstring}\n\n        import imagefiles into alb skip check duplicates true\n\n        return\n    end tell\nend\n\"\"\"\n\nrun(`osascript -e $scr2`)\nThis is again specific to my folder structure with a parent folder Kamera that all albums go in. This works well, the only problem is that it sometimes doesn’t. I run in batches of 30 photos because it’s annoying if something goes wrong in a super-large batch, which loses all the progress made. Sometimes, though, Apple Photos will show a popup window saying that some files couldn’t be imported. I haven’t yet been able to determine why this happens, but this is not detectable from my side. Apple Photos will have to be restarted when that happens, or all following imports will be executed without effect. This means I wouldn’t let this run overnight, I do it once in a while when I can keep an eye on Apple Photos. If I see the problem, I quickly restart it. That does put a small dent in an otherwise convenient workflow, but it’s still much better than anything I had.\nThe other small annoyance is that I cannot delete photos in Apple Photos via AppleScript when I want to replace an existing image with a newer version. I guess they don’t offer this functionality because people who delete their photos irrecoverably by mistake cause customer service too much trouble. But it does feel a bit patronizing, I guess people coding are used to shooting themselves in the foot and there are still plenty of ways left to do it, even without this option.\nWhat I can do is to add the photos I want to delete to another album called “To delete” or something, where I can then select them and delete them via the GUI. That’s also not too terrible, just another small dent."
  },
  {
    "objectID": "pages/2023-09-12-capture-one-photos-sqlite/index.html#conclusion",
    "href": "pages/2023-09-12-capture-one-photos-sqlite/index.html#conclusion",
    "title": "RAW photo library automation with Julia",
    "section": "Conclusion",
    "text": "Conclusion\nOverall I’m pretty happy with the workflow. It means that I get to scroll through all my photos on my iPhone, with Apple’s nice and responsive servers backing all of this, and not my snail-like home internet uplink or some other third-party. I’m left wondering why Capture One and Apple Photos have the AppleScript API gaps and odd behaviors that they have, but I guess my photographer-programmer niche is so small that there are not enough people to voice complaints. Thanks to the makers of Julia, SQLite.jl, DataFrames.jl and other open source softwares that make hacky workarounds like this possible."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html",
    "href": "pages/2022-08-26-pkg-introduction/index.html",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "",
    "text": "When you start using Julia, you will quickly come in contact with Pkg.jl, its package manager. It’s reasonably easy to install a few packages and start using Julia. But from reading questions on Slack and Discourse, many users only start understanding relatively late what commands like instantiate are doing. This post should teach you how you can step beyond a messy global environment and towards neatly packaged local versions that allow you to collaborate more effectively and make your results reproducible."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#getting-started",
    "href": "pages/2022-08-26-pkg-introduction/index.html#getting-started",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Getting started",
    "text": "Getting started\nWhen you install Julia for the first time, there are no environments. Let’s say you installed Julia 1.8. When you start the REPL with the julia command, you will see the standard prompt\njulia&gt; \nFrom there, you get to the Pkg.jl REPL mode by typing ]. The prompt will change to indicate this, by showing the name of the active environment:\n(@v1.8) pkg&gt; \nBut wait, didn’t I just say there are no environments, yet? That’s true, there shouldn’t be any environment files on your computer. You can check the .julia/environments folder, it should be empty. This folder contains all your “shared” environments. You can tell that an environment is shared by the leading @ character in the package REPL prompt, in our case @v1.8 because we use Julia 1.8.\n(Note that if you already have a folder called v1.8, or whatever Julia version you’re using, you can just rename that to v1.8_deactivated or something and restart Julia for the purposes of this tutorial.)\nIf a new environment is activated, this doesn’t yet create any files, and that’s why we don’t have any files in .julia/environments, yet. They only appear once you actually do something with your environment.\nWe can test this quickly. Activate a new environment by typing (@v1.8) pkg&gt; activate MyEnvironment. You won’t see any new files being created in your working directory, as I said this only happens once you manipulate an environment. But the prompt will have changed:\n(@v1.8) pkg&gt; activate MyEnvironment\n  Activating new project at `~/MyEnvironment`\n\n(MyEnvironment) pkg&gt; \nLet’s switch back to the “main” environment @v1.8 for now.\nThe purpose of shared environments is that you can activate them easily from any working directory because they start with @, and Pkg knows to look for them in .julia/environments. For all other environments, you can activate them by name if you are in the directory where they were created, or you have to specify the full path.\nSo we activate @v1.8 again by typing:\n(MyEnvironment) pkg&gt; activate @v1.8\n  Activating new project at `~/.julia/environments/v1.8`\n\n(@v1.8) pkg&gt; \nAs you see, Pkg told us we were activating a new project (another word for environment), because as we saw before, no files did actually exist, yet.\nThere’s another shortcut to activate the main environment, which is activate without an argument:\n(@v1.8) pkg&gt; activate\n  Activating new project at `~/.julia/environments/v1.8`\n\n(@v1.8) pkg&gt;"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#adding-a-package",
    "href": "pages/2022-08-26-pkg-introduction/index.html#adding-a-package",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Adding a package",
    "text": "Adding a package\nLet’s add our first package to our shared @v1.8 environment. For this, we use the add command. I choose the MacroTools package because it has few dependencies.\n(@v1.8) pkg&gt; add MacroTools\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] + MacroTools v0.5.9\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\n\nAs you probably know, after doing this, the MacroTools code has been downloaded onto your system and you can use it in your own code:\njulia&gt; using MacroTools\nSo what actually happened when we ran the add command?\nIn the first line, you can see that the general registry was updated. The general registry (https://github.com/JuliaRegistries/General) is a list of third-party packages that are available to the public, where each package lists all its dependencies and versions. There can be other registries, even private ones, but the general registry is the main one which will be the only one relevant for most users.\nPkg has first updated this list on our computer when we ran add MacroTools so that it knows about the most recent versions of all packages in the ecosystem. You can have a look at it in .julia/registries/ if you want.\nAfter updating the registry, Pkg is Resolving package versions. First, MacroTools latest version at the time of writing, v0.5.9, was added to ~/.julia/environments/v1.8/Project.toml. So at this point in time, finally the environment file I was talking about earlier is being created.\nWe can look at the content of Project.toml:\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nSo this just says that our environment has one dependency declared, which is MacroTools.jl. The UUID string 1914dd2f-81c6... is there because that’s the “real” unique identifier of the package because, e.g., if another hypothetical registry had a different MacroTools, then at least you could specify the one you really want via the UUID.\nPkg also updated the file ~/.julia/environments/v1.8/Manifest.toml. Let’s have a look at this one:\n# This file is machine-generated - editing it directly is not advised\n\njulia_version = \"1.8.0-rc3\"\nmanifest_format = \"2.0\"\nproject_hash = \"e39ab6d265da4acedccb7411db33219b8d7db4fc\"\n\n[[deps.Base64]]\nuuid = \"2a0f44e3-6c83-55bd-87e4-b1978d98bd5f\"\n\n[[deps.MacroTools]]\ndeps = [\"Markdown\", \"Random\"]\ngit-tree-sha1 = \"3d3e902b31198a27340d0bf00d6ac452866021cf\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.9\"\n\n[[deps.Markdown]]\ndeps = [\"Base64\"]\nuuid = \"d6f4376e-aef5-505a-96c1-9c027394607a\"\n\n[[deps.Random]]\ndeps = [\"SHA\", \"Serialization\"]\nuuid = \"9a3f8284-a2c9-5f02-9a11-845980a1fd5c\"\n\n[[deps.SHA]]\nuuid = \"ea8e919c-243c-51af-8825-aaa63cd721ce\"\nversion = \"0.7.0\"\n\n[[deps.Serialization]]\nuuid = \"9e88b42a-f829-5b0c-bbe9-9e923198166b\"\nThe Manifest.toml lists all the packages that were actually installed for you, while the Project.toml only lists the MacroTools dependency.\nYou can think of the two files this way:\n\nProject.toml: What you want.\nManifest.toml: What you get.\n\nThe Project.toml is always the first file being edited when you make environment changes, if that is through the Pkg REPL or manually. The Manifest.toml is then the result of a computation that tries to find compatible versions of all packages specified in the Project.toml and their dependencies. Note that Project.toml can in principle specify impossible demands, like two packages that require incompatible dependencies. A Manifest.toml however should always be in a valid state, if no valid configuration of package dependencies can be resolved, you will just get an error.\nWe can see the dependency graph that Pkg resolved in the Manifest.toml, if we look at the deps fields:\n\n\n\n\n\n\n\nG\n\n\n\nMacroTools\n\nMacroTools v0.5.9\n\n\n\nMarkdown\n\nMarkdown\n\n\n\nMacroTools-&gt;Markdown\n\n\n\n\n\nRandom\n\nRandom\n\n\n\nMacroTools-&gt;Random\n\n\n\n\n\nBase64\n\nBase64\n\n\n\nMarkdown-&gt;Base64\n\n\n\n\n\nSHA\n\nSHA v0.7.0\n\n\n\nRandom-&gt;SHA\n\n\n\n\n\nSerialization\n\nSerialization\n\n\n\nRandom-&gt;Serialization\n\n\n\n\n\n\n\n\n\n\nThe blue node refers to the external package MacroTools, which has a version. The red nodes are standard libraries. Standard libraries are shipped with Julia, so they usually don’t have their own version and only change with each Julia release. You can look at the all the standard libraries in the Julia repository on GitHub. Standard libraries can depend on other standard libraries. SHA is an unusual standard library because it’s hosted externally and has a version. But the version is still fixed for each Julia version via a .version file such as the one for SHA, so most users can just treat it like a normal standard library. In this example, MacroTools depends only on standard libraries, but most other packages depend on other external packages as well.\nYou can check the versions of libraries in your Project.toml and Manifest.toml with the status or st command. With the -m flag you can see the Manifest.toml entries, which can be important for checking which dependencies were resolved.\n(@v1.8) pkg&gt; st\nStatus `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] MacroTools v0.5.9\n\n(@v1.8) pkg&gt; st -m\nStatus `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] MacroTools v0.5.9\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\n\n(@v1.8) pkg&gt; st -m SHA\nStatus `~/.julia/environments/v1.8/Manifest.toml`\n  [ea8e919c] SHA v0.7.0"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#version-numbers",
    "href": "pages/2022-08-26-pkg-introduction/index.html#version-numbers",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Version numbers",
    "text": "Version numbers\nTo understand how dependencies are resolved, you have to understand SemVer versioning. SemVer stands for semantic versioning, which just means that version numbers should be meaningful, not just random labels. The three parts of the version number are major.minor.patch. In Julia, all newer versions with the same major version should have compatible public APIs, so code that works with v1.2.3 should also work with v1.20.5. The exception is major version 0, where each new minor version can be considered potentially breaking. So code that works with v0.2.4 should still work with v0.2.13 but not necessarily with v0.3.0. This is because package developers want to be able to make breaking changes even if they haven’t brought their package to v1.0 yet, a version that usually carries the implication of public API stability and is often reached only after the package has been around for a while."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#adding-specific-variants-of-a-package",
    "href": "pages/2022-08-26-pkg-introduction/index.html#adding-specific-variants-of-a-package",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Adding specific variants of a package",
    "text": "Adding specific variants of a package\nSo far, we have only used the command add MacroTools, which pulled the latest version v0.5.9 into our environment. Sometimes, however, you want a specific variant of a package. That doesn’t necessarily have to be a specific version. It can also be a commit or branch of a certain repository. Let’s try this out with MacroTools.\nWe can install the version v0.5.1 by using the @ syntax:\n(@v1.8) pkg&gt; add MacroTools@0.5.1\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.1\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n⌅ [00ebfdb7] + CSTParser v2.5.0\n⌅ [34da2185] + Compat v2.2.1\n⌅ [864edb3b] + DataStructures v0.17.20\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.1\n  [bac558e1] + OrderedCollections v1.4.1\n  [0796e94c] + Tokenize v0.5.24\n  [0dad84c5] + ArgTools v1.1.1\n  [56f22d72] + Artifacts\n  [ade2ca70] + Dates\n  [8bb1440f] + DelimitedFiles\n  [8ba89e20] + Distributed\n  [f43a241f] + Downloads v1.6.0\n  [7b1f6079] + FileWatching\n  [b77e0a4c] + InteractiveUtils\n  [b27032c2] + LibCURL v0.6.3\n  [76f85450] + LibGit2\n  [8f399da3] + Libdl\n  [37e2e46d] + LinearAlgebra\n  [56ddb016] + Logging\n  [a63ad114] + Mmap\n  [ca575930] + NetworkOptions v1.2.0\n  [44cfe95a] + Pkg v1.8.0\n  [de0858da] + Printf\n  [3fa0cd96] + REPL\n  [1a1011a3] + SharedArrays\n  [6462fe0b] + Sockets\n  [2f01184e] + SparseArrays\n  [10745b16] + Statistics\n  [fa267f1f] + TOML v1.0.0\n  [a4e569a6] + Tar v1.10.0\n  [8dfed614] + Test\n  [cf7118a7] + UUIDs\n  [4ec0a83e] + Unicode\n  [e66e0078] + CompilerSupportLibraries_jll v0.5.2+0\n  [deac9b47] + LibCURL_jll v7.83.1+1\n  [29816b5a] + LibSSH2_jll v1.10.2+0\n  [c8ffd9c3] + MbedTLS_jll v2.28.0+0\n  [14a3606d] + MozillaCACerts_jll v2022.2.1\n  [4536629a] + OpenBLAS_jll v0.3.20+0\n  [83775a58] + Zlib_jll v1.2.12+3\n  [8e850b90] + libblastrampoline_jll v5.1.1+0\n  [8e850ede] + nghttp2_jll v1.47.0+0\n  [3f19e933] + p7zip_jll v17.4.0+0\n        Info Packages marked with ⌃ and ⌅ have new versions available, but those with ⌅ cannot be upgraded. To see why use `status --outdated -m`\n\nYou can see that we got a ton of new dependencies. This happened because MacroTools managed to cut the number of packages it depends on a lot over time, so the older version pulls in much more.\nIf we take a look at the new Manifest.toml entry for MacroTools, we see:\n[[deps.MacroTools]]\ndeps = [\"CSTParser\", \"Compat\", \"DataStructures\", \"Test\", \"Tokenize\"]\ngit-tree-sha1 = \"d6e9dedb8c92c3465575442da456aec15a89ff76\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.1\"\nThis just goes to show that even between patch versions of a package, which should all follow the same public API, the dependencies can change a lot.\nIf you look at the Project.toml, you will see that it hasn’t changed. The version requirement was just enforced during this one dependency resolution, and won’t be remembered or enforced again in future Pkg operations.\nLet’s try one other syntax, which is the one for choosing a specific commit or branch from a repository. In this case, we use the commit 639d1a6, but we could also use something like master to fetch the latest commit on that branch.\n(@v1.8) pkg&gt; add MacroTools#639d1a6\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] ~ MacroTools v0.5.1 ⇒ v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [00ebfdb7] - CSTParser v2.5.0\n  [34da2185] - Compat v2.2.1\n  [864edb3b] - DataStructures v0.17.20\n  [1914dd2f] ~ MacroTools v0.5.1 ⇒ v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n  [bac558e1] - OrderedCollections v1.4.1\n  [0796e94c] - Tokenize v0.5.24\n  [0dad84c5] - ArgTools v1.1.1\n  [56f22d72] - Artifacts\n  [ade2ca70] - Dates\n  [8bb1440f] - DelimitedFiles\n  [8ba89e20] - Distributed\n  [f43a241f] - Downloads v1.6.0\n  [7b1f6079] - FileWatching\n  [b77e0a4c] - InteractiveUtils\n  [b27032c2] - LibCURL v0.6.3\n  [76f85450] - LibGit2\n  [8f399da3] - Libdl\n  [37e2e46d] - LinearAlgebra\n  [56ddb016] - Logging\n  [a63ad114] - Mmap\n  [ca575930] - NetworkOptions v1.2.0\n  [44cfe95a] - Pkg v1.8.0\n  [de0858da] - Printf\n  [3fa0cd96] - REPL\n  [1a1011a3] - SharedArrays\n  [6462fe0b] - Sockets\n  [2f01184e] - SparseArrays\n  [10745b16] - Statistics\n  [fa267f1f] - TOML v1.0.0\n  [a4e569a6] - Tar v1.10.0\n  [8dfed614] - Test\n  [cf7118a7] - UUIDs\n  [4ec0a83e] - Unicode\n  [e66e0078] - CompilerSupportLibraries_jll v0.5.2+0\n  [deac9b47] - LibCURL_jll v7.83.1+1\n  [29816b5a] - LibSSH2_jll v1.10.2+0\n  [c8ffd9c3] - MbedTLS_jll v2.28.0+0\n  [14a3606d] - MozillaCACerts_jll v2022.2.1\n  [4536629a] - OpenBLAS_jll v0.3.20+0\n  [83775a58] - Zlib_jll v1.2.12+3\n  [8e850b90] - libblastrampoline_jll v5.1.1+0\n  [8e850ede] - nghttp2_jll v1.47.0+0\n  [3f19e933] - p7zip_jll v17.4.0+0\nNote that even though the version printed for MacroTools is again 0.5.9, this doesn’t necessarily mean that we are on the same commit as the one pointed to by the version 0.5.9 in the registry. It just means that Pkg cloned the repository, checked out the commit with hash 639d1a6 and found the version specifier 0.5.9 in MacroTools’s own Project.toml file. Therefore, infinitely many code versions of a package can be treated as version X.Y.Z by Pkg, but X.Y.Z itself refers only to exactly one version. This distinction is important to remember when developing and editing a package, but more about that later.\nIf we take another look at our Manifest.toml, we can see the following entry for MacroTools:\n[[deps.MacroTools]]\ndeps = [\"Markdown\", \"Random\"]\ngit-tree-sha1 = \"465a4803356bcb11f6eb97df992680f13a9ba776\"\nrepo-rev = \"639d1a6\"\nrepo-url = \"https://github.com/FluxML/MacroTools.jl.git\"\nuuid = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nversion = \"0.5.9\"\nThis time, the URL of the repository was recorded, as well as the revision, which was 639d1a6. This is because as soon as you specify a revision in the add command, Pkg knows you’re operating outside of the registry, so it cannot rely on the repository information stored there for MacroTools.\n(Note that you can also install unregistered packages, or forks of registered packages this way, by doing add https://the_url_to_the_git_repository.)\nThe manifest needs to store the url and revision in order to make the project reproducible by someone else. Let’s actually look at what reproducing an environment looks like:"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#reproducing-an-environment",
    "href": "pages/2022-08-26-pkg-introduction/index.html#reproducing-an-environment",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Reproducing an environment",
    "text": "Reproducing an environment\nLet’s say you have written some code relying on the specific MacroTools version we added via add MacroTools#639d1a6 and want your colleague to be able to run that code with the exact packages installed that we used at the time.\nWhich files do they need to reproduce the state of your environment? Not just the Project.toml, because remember, it still only contains this information:\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nWe need to also send the Manifest.toml because it records the exact versions of all packages. Let’s pretend we are our colleague, and we just received a Project.toml and Manifest.toml file. How do we actually get the environment installed?\nLet’s copy the files into a new folder we call ColleagueEnv in our current working directory.\nTo pretend we’re the colleague who just uses Julia for the first time, we also delete the .julia/packages/MacroTools folder in which the downloaded source code of MacroTools was stored.\nNote that this means that the source code is not part of an environment but stored centrally. It would be pretty wasteful to download the same sources over and over just because you’re using different local environments.\nLet’s now restart Julia and activate the ColleagueEnv environment:\n(@v1.8) pkg&gt; activate ./ColleagueEnv\n  Activating project at `~/ColleagueEnv`\n\nWe can check the installed packages via st -m:\n(ColleagueEnv) pkg&gt; st -m\nStatus `~/ColleagueEnv/Manifest.toml`\n→ [1914dd2f] MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#master`\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\nInfo Packages marked with → are not downloaded, use `instantiate` to download\n\nIf we were trying to just run some code using MacroTools now, this would happen:\njulia&gt; using MacroTools\nERROR: ArgumentError: Package MacroTools [1914dd2f-81c6-5fcd-8719-6d5c9610ff09] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n\nStacktrace:\n [1] _require(pkg::Base.PkgId)\n   @ Base ./loading.jl:1306\n [2] _require_prelocked(uuidkey::Base.PkgId)\n   @ Base ./loading.jl:1200\n [3] macro expansion\n   @ ./loading.jl:1180 [inlined]\n [4] macro expansion\n   @ ./lock.jl:223 [inlined]\n [5] require(into::Module, mod::Symbol)\n   @ Base ./loading.jl:1144\nSo we need to follow the advice already printed twice for us, and call instantiate. This will download everything specified in the Manifest.toml exactly as it was recorded there. You can actually be sure that it’s exactly the same because the Manifest.toml stores git tree hashes of each dependency. Unless someone deletes these specific parts of the repository you will be able to download the source exactly as it was:\n(ColleagueEnv) pkg&gt; instantiate\nPrecompiling project...\n  ✓ MacroTools\n  1 dependency successfully precompiled in 1 seconds\n\n(ColleagueEnv) pkg&gt; st -m\nStatus `~/ColleagueEnv/Manifest.toml`\n  [1914dd2f] MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#master`\n  [2a0f44e3] Base64\n  [d6f4376e] Markdown\n  [9a3f8284] Random\n  [ea8e919c] SHA v0.7.0\n  [9e88b42a] Serialization\n\nNow we don’t get a warning anymore, our dependencies have been downloaded correctly. You will find MacroTools downloaded into the .julia/packages folder again."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#packages-and-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#packages-and-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Packages and environments",
    "text": "Packages and environments\nPackages and normal environments are pretty similar. Each package must have a Project.toml which specifies its name, UUID, version and dependencies. The easiest way to make a package to test this out, is to use the generate command of the Pkg REPL.\nLet’s restart Julia and remove MacroTools from our main environment so it is empty:\n(@v1.8) pkg&gt; rm MacroTools\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [1914dd2f] - MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] - MacroTools v0.5.9 `https://github.com/FluxML/MacroTools.jl.git#639d1a6`\n  [2a0f44e3] - Base64\n  [d6f4376e] - Markdown\n  [9a3f8284] - Random\n  [ea8e919c] - SHA v0.7.0\n  [9e88b42a] - Serialization\nNow, we generate a new package called MyPackage:\n(@v1.8) pkg&gt; generate MyPackage\n  Generating  project MyPackage:\n    MyPackage/Project.toml\n    MyPackage/src/MyPackage.jl\n\nAs you can see, a Project.toml file was generated in the MyPackage directory.\nLet’s have a look at this one:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name &lt;your@email.com&gt;\"]\nversion = \"0.1.0\"\nThe only difference from a basic package environment to a normal environment are those four fields. If we want to use MacroTools in our package, we can add it manually to a deps section in the Project.toml, or we use the Pkg REPL. For that, we first activate the package as an environment, then we add MacroTools.\n(@v1.8) pkg&gt; activate MyPackage/\n  Activating project at `~/MyPackage`\n\n(MyPackage) pkg&gt; add MacroTools\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n   Installed MacroTools ─ v0.5.9\n    Updating `~/MyPackage/Project.toml`\n  [1914dd2f] + MacroTools v0.5.9\n    Updating `~/MyPackage/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\nPrecompiling project...\n  ✓ MacroTools\n  ✓ MyPackage\n  2 dependencies successfully precompiled in 1 seconds\n\nThe Project.toml now looks like this:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name &lt;your@email.com&gt;\"]\nversion = \"0.1.0\"\n\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\nIn the file MyPackage/src/MyPackage.jl, we can now import MacroTools and work with it. Let’s change the content of that file to:\nmodule MyPackage\n\nimport MacroTools\n\nfunction test()\n    MacroTools.@capture :(1 + 2) x_ + y_\n    @show x\n    @show y\n    return\nend\n\nend # module MyPackage\nWe can now import or using our package and verify that MacroTools can be used by its source code:\njulia&gt; using MyPackage\n\njulia&gt; MyPackage.test()\nx = 1\ny = 2\n\nThat worked!"
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#the-develop-command",
    "href": "pages/2022-08-26-pkg-introduction/index.html#the-develop-command",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "The develop command",
    "text": "The develop command\nLet’s restart Julia now, which will bring us back to the main environment. Let’s try again to import our package:\njulia&gt; using MyPackage\nERROR: ArgumentError: Package MyPackage not found in current path.\n- Run `import Pkg; Pkg.add(\"MyPackage\")` to install the MyPackage package.\nStacktrace:\n [1] macro expansion\n   @ ./loading.jl:1163 [inlined]\n [2] macro expansion\n   @ ./lock.jl:223 [inlined]\n [3] require(into::Module, mod::Symbol)\n   @ Base ./loading.jl:1144\n\nThis doesn’t work, because our main environment doesn’t have MyPackage installed. You can use MyPackage as long as you have its own environment activated, but outside of that it is not visible.\nWe can change that by using the develop or dev command of the Pkg REPL, which will install and track MyPackage:\n(@v1.8) pkg&gt; dev ./MyPackage/\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [025f59cc] + MyPackage v0.1.0 `../../../MyPackage`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [1914dd2f] + MacroTools v0.5.9\n  [025f59cc] + MyPackage v0.1.0 `../../../MyPackage`\n  [2a0f44e3] + Base64\n  [d6f4376e] + Markdown\n  [9a3f8284] + Random\n  [ea8e919c] + SHA v0.7.0\n  [9e88b42a] + Serialization\n\nGreat, that worked. Now we can access MyPackage again:\njulia&gt; using MyPackage\n[ Info: Precompiling MyPackage [025f59cc-7e1c-467d-8f56-70157e1cbbbb]\n\njulia&gt; MyPackage.test()\nx = 1\ny = 2\n\nWhy would we want to do this, use a separate environment to access our package environment? It’s because we probably want to use other packages that should not be dependencies of MyPackage while developing it. For example, a data analysis package could be developed while using a package like RDatasets.jl which supplies test datasets."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#compatibility-bounds",
    "href": "pages/2022-08-26-pkg-introduction/index.html#compatibility-bounds",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Compatibility bounds",
    "text": "Compatibility bounds\nCurrently, MyPackage does not specify the versions of MacroTools with which it is compatible. That is usually not a good idea, in fact, the general registry doesn’t allow packages to be registered if they don’t specify upper compatibility boundaries for each dependency. That makes sense because you don’t know if your package will be compatible with all future versions of your dependencies, so it makes sense to cap the compatibility to the point where you have tested everything works.\nLet’s pretend we tested our package only up to MacroTools version 0.5.8. We can write this requirement into the Project.toml of MyPackage:\nname = \"MyPackage\"\nuuid = \"025f59cc-7e1c-467d-8f56-70157e1cbbbb\"\nauthors = [\"Your Name &lt;your@email.com&gt;\"]\nversion = \"0.1.0\"\n\n[deps]\nMacroTools = \"1914dd2f-81c6-5fcd-8719-6d5c9610ff09\"\n\n[compat]\nMacroTools = \"&lt;0.5.9\"\nBut this change is not picked up automatically by the @v1.8 environment. To recompute the dependency graph and throw away the old Manifest.toml, we can run update or up:\n(@v1.8) pkg&gt; up\n    Updating registry at `~/.julia/registries/General.toml`\n   Installed MacroTools ─ v0.5.8\n  No Changes to `~/.julia/environments/v1.8/Project.toml`\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n⌃ [1914dd2f] ↓ MacroTools v0.5.9 ⇒ v0.5.8\n        Info Packages marked with ⌃ have new versions available\nPrecompiling project...\n  ✓ MacroTools\n  ✓ MyPackage\n  2 dependencies successfully precompiled in 2 seconds\n  \nAs you can see, the MacroTools package was correctly downgraded to v0.5.8.\nWhat would happen if we now tried to install v0.5.9 into the main environment?\n(@v1.8) pkg&gt; add MacroTools@0.5.9\n   Resolving package versions...\nERROR: Unsatisfiable requirements detected for package MacroTools [1914dd2f]:\n MacroTools [1914dd2f] log:\n ├─possible versions are: 0.4.3-0.5.9 or uninstalled\n ├─restricted to versions 0.0.0-0.5.8 by MyPackage [025f59cc], leaving only versions 0.4.3-0.5.8\n │ └─MyPackage [025f59cc] log:\n │   ├─possible versions are: 0.1.0 or uninstalled\n │   └─MyPackage [025f59cc] is fixed to version 0.1.0\n └─restricted to versions 0.5.9 by an explicit requirement — no versions left\n\nWe get a version compatibility conflict. It is not possible to reconcile the requirement of adding MacroTools 0.5.9 with the fact that it is only allowed to reach up to 0.5.8 for MyPackage.\nCompatibility conflicts are the main reason why you should give each of your projects its own local environment instead of always using the global one. First of all, you’re more and more likely to end up with old versions or compatibility clashes, the more packages you install. Second, if you inadvertently update your main environment for project B, but later go back to project A, it could very well be that the new package versions are now incompatible with the code you wrote for A at the time. You don’t want to tangle all your projects up together, so just make separate environments for each."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#differences-between-add-and-develop",
    "href": "pages/2022-08-26-pkg-introduction/index.html#differences-between-add-and-develop",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Differences between add and develop",
    "text": "Differences between add and develop\nIn our examples, we have seen the add and develop commands when dealing with packages we want to install.\nBoth add and dev can be used to include packages in your environment. Both can take a local path, or the name of a registered package, or a link to a repository as sources. So why do we have two separate but similar commands?\nThe difference is that add treats packages as fixed, read-only resources. When you add a package, no matter if local or remote, each version is copied to an internal Julia folder where it should not be modified anymore.\nWhen you dev a local package, it stays where it is and can be modified by you. You just have to remember to restart Julia to load any changes you make (unless they can be auto-reloaded by Revise.jl, which you should check out if you haven’t seen it yet), and to update the environment in case you make changes to the Project.toml like new dependencies or compatibility bounds. When you use dev, Julia is said to “track” that package.\nBecause you’re expected to make changes to code when you use dev, Julia copies packages that you develop for the first time by specifying its name or URL (for example dev MacroTools or dev https://github.com/FluxML/MacroTools.jl) into a special folder at .julia/dev. Here, you can access them with your editor of choice, make changes, and sync those back to GitHub or other version control systems.\nNote that if you dev MacroTools in one local environment, and later dev MacroTools in a different environment, Julia will by default re-use the same repository at .julia/dev. If the first environment was already quite old and you haven’t pulled the new changes in a while, you’ll probably be surprised that you get that old version when you run dev in the fresh environment! Therefore, it can make sense to use separate local copies of packages you want to work on, if you anticipate that you will work on them in several different contexts. To do this, you can either clone a repository into a local folder, for example with git clone https://github.com/FluxML/MacroTools.jl and then run dev the_local_folder. The other option is running dev --local MacroTools, which copies the developed package into the working directory, not .julia/dev."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#stacked-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#stacked-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Stacked environments",
    "text": "Stacked environments\nThere’s another behavior of environments that is potentially very confusing for beginners, and it’s called “stacked environments”. Let’s restart Julia again, and add the package Infiltrator to the main environment:\n(@v1.8) pkg&gt; add Infiltrator\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.8/Project.toml`\n  [5903a43b] + Infiltrator v1.6.1\n    Updating `~/.julia/environments/v1.8/Manifest.toml`\n  [5903a43b] + Infiltrator v1.6.1\n  [b77e0a4c] + InteractiveUtils\n  [3fa0cd96] + REPL\n  [6462fe0b] + Sockets\n  [cf7118a7] + UUIDs\n  [4ec0a83e] + Unicode\nNow we activate the environment of MyPackage:\n(@v1.8) pkg&gt; activate MyPackage\n  Activating project at `~/MyPackage`\n\nLet’s see what happens if we load Infiltrator:\njulia&gt; using Infiltrator\nIt worked. But why? Infiltrator is not available in MyPackage’s Project.toml.\nThe reason is that Julia can import packages from multiple environments at the same time. This depends on the LOAD_PATH global variable. Let’s have a look:\njulia&gt; LOAD_PATH\n3-element Vector{String}:\n \"@\"\n \"@v#.#\"\n \"@stdlib\"\n\nThe first entry, \"@\", means “active environment”, so the first place where Julia looked for Infiltrator was in MyPackage’s environment, where it didn’t find it.\nThe second entry, \"@v#.#\" means “the shared environment of this Julia version”, in our case this is @v1.8. That’s why I kept calling this the “main” environment, not only because it’s the default one, but also because it’s always available by default due to the LOAD_PATH configuration. This is where Julia found Infiltrator and loaded it.\nThe third entry, \"@stdlib\", refers to the list of standard libraries that belongs to the current Julia version. This is the reason why we can do using Statistics or using REPL in a new Julia session, even if our main environment is empty.\nOne potential confusion comes from the fact that a user can activate a package environment and work there under the assumption that only package dependencies are available to import. This might hide the fact that some of the included packages are drawn in from the main environment, which will lead to an error later, if the package is installed to a new environment and can’t access the dependency anymore.\nAnd there’s another, even trickier case. Let’s say you develop DevelopingPackage which depends on HelperDependency at version 3.0. But for debugging, you also have installed DebugPackage in your main environment, which happens to depend on HelperDependency too, but compat bound to version 2.0. Now, the main environment’s Manifest.toml will list HelperDependency v2.0 and your package development environment will list HelperDependency v3.0. If you start Julia in the main environment and type using DebugPackage, Julia will also load HelperDependency at version 2.0 in the background. Now, you switch environments and type using DevelopingPackage. Julia will now try to load DevelopingPackage but it cannot load HelperDependency v3.0 because v2.0 is already loaded. Now you’ll get undefined behavior, because the package versions might be similar enough that you don’t notice anything, but they might be so different that you get UndefVarErrors or subtle bugs in behavior.\nBecause of these common footguns, the best practice is to use the main environment sparingly. Infiltrator is a good example for a package you can probably install there without issues. It’s a debugging package and rarely needed as a dependency for another package, and it doesn’t have non-standard-library dependencies, which means there’s no potential for the dependency loading issue mentioned above. On the other hand it’s very useful to have available without further effort when developing, so it can be a matter of convenience.\nIf you really want to make sure that only the packages from your currently activated project are accessible, you can remove other entries from the load path.\nTo demonstrate this, if we empty the load path we can’t load any package at all, neither Infiltrator from @v1.8, nor MyPackage from our active environment, nor the standard library Statistics:\njulia&gt; empty!(LOAD_PATH)\nString[]\n\njulia&gt; using Infiltrator\n │ Package Infiltrator not found, but a package named Infiltrator is available\n │ from a registry. \n │ Install package?\n │   (MyPackage) pkg&gt; add Infiltrator \n └ (y/n/o) [y]: ERROR: ArgumentError: Package Infiltrator not found in current path, maybe you meant `import/using .Infiltrator`.\n- Otherwise, run `import Pkg; Pkg.add(\"Infiltrator\")` to install the Infiltrator package.\n\njulia&gt; using MyPackage\nERROR: ArgumentError: Package MyPackage not found in current path.\n- Run `import Pkg; Pkg.add(\"MyPackage\")` to install the MyPackage package.\n\njulia&gt; using Statistics\nERROR: ArgumentError: Package Statistics not found in current path.\n- Run `import Pkg; Pkg.add(\"Statistics\")` to install the Statistics package."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#temporary-environments",
    "href": "pages/2022-08-26-pkg-introduction/index.html#temporary-environments",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Temporary environments",
    "text": "Temporary environments\nOne thing that’s useful for quick tests are temporary environments. If you read about a new package and quickly want to try it, but don’t want to mess with your main environment or clutter your working directory with environment files, you can use activate --temp:\n(v1.8) pkg&gt; activate --temp\n  Activating new project at `/var/folders/z5/r5q6djwn5g10k3w279bn37700000gn/T/jl_e4klnB`\n\n(jl_e4klnB) pkg&gt; \nThis environment will only exist until the Julia process exits, so it’s perfect to run something once and then forget about it."
  },
  {
    "objectID": "pages/2022-08-26-pkg-introduction/index.html#conclusion",
    "href": "pages/2022-08-26-pkg-introduction/index.html#conclusion",
    "title": "Pkg.jl and Julia Environments for Beginners",
    "section": "Conclusion",
    "text": "Conclusion\nThis was a short tour of Pkg and its main functions. I hope it has become more clear how environments work and why you shouldn’t rely on a single global one. It’s quite easy to make one environment per project and the text files created use effectively no space, so there’s no downside to doing this.\nFor more info, have a look at some of these sources:\n\nPkg.jl documentation.\nDrWatson.jl, a tool that tries to make the process of setting up reproducible projects easier.\nTestEnv.jl which helps with the problem of stacked environments in the context of tests (not covered here).\nPkgTemplates.jl which makes creating packages easier."
  },
  {
    "objectID": "pages/2020-10-23-julia-bridge/index.html",
    "href": "pages/2020-10-23-julia-bridge/index.html",
    "title": "Julia Helps To Bridge The Gap Between User and Creator",
    "section": "",
    "text": "You might have heard about Julia, the language often praised for the C-like performance it can attain while keeping a clean syntax reminiscent of Python. In this blog post, I want to share a different opinion why I like using Julia, which is only tangentially related to its pure performance. It is about the community Julia enables and how that could have a beneficial influence on the way scientific software is written.\nFirst off, I am not a trained computer scientist. Almost nobody in my research fields, psychology and neuroscience, is a trained computer scientist. But everybody needs to code nowadays to do research. Experiments are setup with code, data is analysed with code, graphs are made with code. So how does that work out if nobody is really trained for coding?\nIt leads to a situation where people waste time and often produce inferior results because they don’t really grasp the tools they are using. Code is often of low quality, neither version controlled, maintainable nor reproducible. Matlab, R and Python ecosystems offer tools that allow researchers to focus on their direct interest, the data, and spend less time fighting with the compilers and complicated syntax of C++ and Fortran. But this “convenience layer” contributes to a situation where people use tools without a deeper understanding what they are doing, without an idea of what to do when those tools are not enough. We have powerful packages with relatively user-friendly API’s at our disposal in each dynamic language of choice. But the important and performant parts are written in C, C++ and Fortran, hidden from view.\nIt is not easy to find out how things work under the hood in Python, R or Matlab. I think that this creates a big gap between users and creators of scientific tools.\nStudents in a university R or Python data analysis course will probably learn a bit about loops and conditionals first, because that’s just how everyone learning to code starts. But after that first phase, they will quickly move on to learning APIs of packages like dplyr, ggplot, pandas, because that’s what’s actually used by everybody. These API’s tend to be quite removed from the basic building blocks of each language (like the common but non-standard %&gt;% syntax in R). If those tools don’t offer something out of the ordinary as a pre-packaged functionality, the students are out of luck. They know that they shouldn’t attempt to write any serious low-level analysis methods in R or Python directly, because that will probably be slow, and their tools of choice are also not made like that. One of the first things Python, R and Matlab novices learn is “Vectorize everything! Don’t write for-loops, they are slow!”. How surprised would they be to find out that the inside of pandas, dplyr and co is full of for-loops, because they are indispensable building blocks in compiled languages?\nOne such example of the boundaries of existing packages I’ve encountered in my previous work was when I analysed head movement data with Python’s pandas library. I really wanted a column in my dataframe that had one rotation matrix per row, describing head orientation over time. But that was not possible to do effectively because a rotation matrix is just not a data type that pandas expects you to store in a column. At every corner my “weird” datatype caused problems with underlying assumptions of pandas, or numpy or matplotlib. In Julia, it would have been really easy to make a Vector with 3x3 matrices from StaticArrays.jl. DataFrames.jl doesn’t care what your column vectors contain. To me, the point was not even to have the fastest solution, just to have a solution that cleanly expressed my intent.\nThe two-language problem is often presented as an inconvenience to researchers because of its time cost. I think it is a bit more than that. True, it takes a lot of time to figure out a solution to a problem in a dynamic language and then transfer it faithfully to a compiled language, to write bug-free bindings and package everything up for reuse. Julia tries to solve that problem, and it does very well to bridge the gap between a glue language with simple syntax and a serious numerical powerhouse. Countless benchmarks can attest to its speed. But when we focus only at how much time it takes to use two languages, I think we overlook what kind of effect a language gap has on research communities in this age of code.\nThe Julia community is filled with people from diverse scientific backgrounds. Many of them, like me, are not computer scientists. That doesn’t stop them from being involved in writing serious low level packages. And if they are not writing packages themselves, they are often helping by filing issues and creating PRs, adding their own perspectives on design questions. They do this even for the Julia language itself, if they find bugs or API inconsistencies. When I was using Matlab, Python and R, I didn’t see other researchers contribute to the fundamentals of their respective ecosystems in this way. In Julia, I see it all the time.\nThis is possible, in my opinion, because there is a continuous path from surface-level glue code to close-to-the-metal high-performance code in Julia, which can be discovered almost playfully - usually driven by the desire to reduce the number of allocations or runtime of a small function. In Julia, novices can learn first principles in a beginner friendly way, without caring about types, writing code that looks basically like Python. These first principles don’t lose their importance when serious packages are discovered. They instead become ever more powerful, the more knowledge a new user absorbs, because they can be combined in more and more flexible and innovative ways. As another example, if you use Stan from R, you have to feed it a script in a different language, while your Turing.jl models can be written in normal Julia. There’s really no limit to what you can send through Bayesian inference this way. Additionally, advanced topics like metaprogramming and optimization are always only a few steps away, and interesting lessons about one’s own code or the inner workings of Julia can be learned just by applying a couple of macros such as @code_warntype here and there. A transformation from beginner to expert code sometimes goes only through a couple minor changes like adding @inbounds in strategical places, or minimizing the use of allocations.\nFor example, with Revise.jl and the @edit macro, it’s quite simple to manipulate even Base functions on the fly, and play around with different implementations of Julia’s fundamental building blocks. The multiple dispatch paradigm makes it possible to inject functionality deep into third party code and to connect one’s homegrown implementations with the work of others in a way that I have never seen in Python, R or Matlab. This is not brittle tampering like, e.g., monkeypatching in Python, but allows you to meaningfully extend the available functionality if you want to. Packages are specifically written to be extensible by others, each dispatch presents an opportunity for third parties to hook into. One person might have a small idea, but through Julia’s ability for composition, it can easily become part of something bigger (like the often cited Differential Equations + Measurements + Plot Recipe combo).\nI think Julia’s gentle learning curve and raw processing power are an invitation to domain experts outside of computer science to help write the software their fields need. Personally, it makes me feel more powerful and self-sufficient to work in a dynamic language that can not only give access to other people’s well written packages (written in Julia, but also R, Python and Matlab through RCall.jl, PyCall.jl and MATLAB.jl, respectively). It also allows me to write my own, and not just for toy problems but theoretically scalable even to supercomputers.\nI hope that in the future Julia loses the perception of being a niche language for numerics, which might discourage people who don’t need just that from trying it. Instead, I would frame it as a powerful general programming language that offers something for everyone from beginners to experts and encourages collaboration and code reuse through its extensible multiple dispatch paradigm. If researchers write more algorithms in high-level Julia and not in low-level C++, this could make them more accessible for novices and easier to check for other researchers, because Julia shares the same “pseudo-code” qualities of Python (which doesn’t actually look so clean anymore if everything is prefixed by np.). The Julia community also highly values CI and good test coverage and I hope that such things become more mainstream in the future, because every scientist that works with code can benefit from adopting these best practices.\nI wrote this post because I felt these aspects tend to be under-represented when Julia is discussed. Sometimes, the focus on micro-benchmarks and the resulting exaggerated or one-sided claims of superior performance expectedly cause users of other languages to go into defense mode. That’s not necessary in my opinion. Yes, Python R and Matlab also have amazing fast packages that enable people to do great research. But these languages are also fundamentally limited in how low-level users can reach, and they don’t allow for the same freedom to create beautiful and generic implementations that still harness all available computing power. They don’t allow scientists to bridge the gap from user to creator quite as well. And bridging that gap holds a lot of potential, especially in today’s world where everything is about code."
  }
]